.\" Automatically generated by Pandoc 2.17.1.1
.\"
.\" Define V font for inline verbatim, using C font in formats
.\" that render this, and otherwise B font.
.ie "\f[CB]x\f[]"x" \{\
. ftr V B
. ftr VI BI
. ftr VB B
. ftr VBI BI
.\}
.el \{\
. ftr V CR
. ftr VI CI
. ftr VB CB
. ftr VBI CBI
.\}
.TH "Principal Component Analysis" "" "" "" ""
.hy
.SH NAME
.PP
PCA - It\[cq]s full form is Principal Component Analysis.
It is an unsupervised learning algorithm that is used for dimensionality
reduction in machine learning.
.SH SYNOPSIS
.IP
.nf
\f[C]
frovedis.mllib.decomposition.pca(n_components=None, copy=True, whiten=False,
                                 svd_solver=\[aq]auto\[aq], tol=0.0, iterated_power=\[aq]auto\[aq],
                                 random_state=None)  
\f[R]
.fi
.SS Public Member Functions
.PP
fit(X, y = None)
.PD 0
.P
.PD
fit_transform(X)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
inverse_transform(X)
.PD 0
.P
.PD
is_fitted()
.PD 0
.P
.PD
load(path, dtype)
.PD 0
.P
.PD
load_binary(path, dtype)
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
save(path)
.PD 0
.P
.PD
save_binary(path)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
transform(X)
.SH DESCRIPTION
.PP
It is one of the popular tools that is used for exploratory data
analysis and predictive modeling.
It is a technique to draw strong patterns from the given dataset by
reducing the variances.
.PP
PCA generally tries to find the lower-dimensional surface to project the
high-dimensional data.
.PP
For dimensionality reduction, it uses Singular Value Decomposition of
the data.
The input data is centered but not scaled for each feature before
applying the SVD.
.PP
This module provides a client-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as Scikit-learn PCA interface, but
it doesn\[cq]t have any dependency with Scikit-learn.
It can be used simply even if the system doesn\[cq]t have Scikit-learn
installed.
Thus in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for PCA on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When transform-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.PP
\f[B]Like Scikit-learn, PCA in frovedis only supports dense input data.
However, when sparse input is provided in frovedis, internally, it will
be converted into frovedis-like dense input before sending it to
frovedis server.\f[R]
.SS Detailed Description
.SS 1. PCA()
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]n_components\f[B]\f[R]: It accepts a positive integer value
as parameter that specifies the number of components to keep.
It must be in range \f[B][1, min(n_samples_, n_features_) - 1)\f[R].
(Default: None)
.PD 0
.P
.PD
When it is None (not specified explicitly), it wil be set as
\f[B]min(n_samples_, n_features_) - 1\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]copy\f[B]\f[R]: It is a boolean parameter that specifies
whether input data passed is overwritten or not during fitting.
(Default: True)
.PD 0
.P
.PD
When it is False (specified explicitly), data passed to fit() is
overwritten and running fit(X).transform(X) will not yield the expected
results, so fit_transform(X) is to be used instead.
.PD 0
.P
.PD
\f[B]\f[BI]whiten\f[B]\f[R]: It is a boolean parameter.
It removes some information from the transformed signal (the relative
variance scales of the components) but can sometime improve the
predictive accuracy of the downstream estimators.
(Default: False)
.PD 0
.P
.PD
When it is True (specified explicitly), the \f[B]components_\f[R]
vectors are multiplied by the square root of \f[B]n_samples\f[R] and
then divided by the singular values to ensure uncorrelated outputs with
unit component-wise variances.
.PD 0
.P
.PD
\f[B]\f[BI]svd_solver\f[B]\f[R]: It accepts a string value as parameter
that specifies which solver to use.
\f[B]Currently it supports only `arpack' implementation of svd.\f[R]
(Default: `auto')
.PD 0
.P
.PD
When it is auto, then \f[B]svd_solver = `arpack'.\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]tol\f[B]\f[R]: This is an unused parameter.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[BI]iterated_power\f[B]\f[R]: This is an unused parameter.
(Default: `auto')
.PD 0
.P
.PD
\f[B]\f[BI]random_state\f[B]\f[R]: This is an unused parameter.
(Default: None)
.PP
\f[B]Attributes\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]components_\f[B]\f[R]: It is a numpy ndarray of shape
\f[B](n_components, n_features)\f[R].
It specifies the principal axes in feature space, representing the
directions of maximum variance in the data.
.PD 0
.P
.PD
\f[B]\f[BI]explained_variance_\f[B]\f[R]: It is a numpy ndarray of shape
\f[B](n_components,)\f[R].
It specifies the variance of the training samples transformed by a
projection to each component.
.PD 0
.P
.PD
\f[B]\f[BI]explained_variance_ratio_\f[B]\f[R]: It is a numpy ndarray of
shape \f[B](n_components,)\f[R].
It specifies the percentage of variance explained by each of the
selected components.
If \f[B]`n_components'\f[R] is not set, then all components are stored
and the sum of the ratios is equal to 1.0.
.PD 0
.P
.PD
\f[B]\f[BI]mean_\f[B]\f[R]: It is a numpy ndarray of shape
\f[B](n_features,)\f[R].
It specifies the per-feature empirical mean, estimated from the training
set.
It is equal to \f[B]X.mean(axis=0)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]n_components_\f[B]\f[R]: It is a positive integer value that
specifies the estimated number of components.
.PD 0
.P
.PD
\f[B]\f[BI]n_features_\f[B]\f[R]: It is a positive integer value that
specifies the number of features in the training data (X).
.PD 0
.P
.PD
\f[B]\f[BI]n_samples_\f[B]\f[R]: It is a positive integer value that
specifies the number of samples in the training data (X).
.PD 0
.P
.PD
\f[B]\f[BI]noise_varaince_\f[B]\f[R]: It is a float (float32) value that
specifies the estimated noise covariance.
It is required to compute the estimated data covariance and score
samples.
It is equal to the \f[B]average of (min(n_features, n_samples) -
n_components)\f[R] smallest eigenvalues of the covariance matrix of
input matrix (X).
.PD 0
.P
.PD
\f[B]\f[BI]singular_values_\f[B]\f[R]: It is a numpy ndarray of shape
\f[B](n_components,)\f[R] that specifies the singular values
corresponding to each of the selected components.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It initializes a PCA object with the given parameters.
.PP
The parameters: \[lq]tol\[rq], \[lq]iterated_power\[rq] and
\[lq]random_state\[rq] are simply kept in to make the interface uniform
to the Scikit-learn PCA module.
They are not used in frovedis implementation internally.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 2. fit(X, y = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object of int, float or double (float64) type values.
It can also be an instance of FrovedisCRSMatrix for sparse data and
FrovedisRowmajorMatrix for dense data of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It will fit the model with input matrix (X).
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)
            
# fitting input matrix on PCA object  
from frovedis.mllib.decomposition import PCA
pca = PCA().fit(mat)  
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)  

# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.  
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
rmat = FrovedisRowmajorMatrix(mat)  

# PCA with pre-constructed frovedis-like inputs  
from frovedis.mllib.decomposition import PCA
pca = PCA().fit(rmat)  
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 3. fit_transform(X, y = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object of int, float or double (float64) type values.
It can also be an instance of FrovedisCRSMatrix for sparse data and
FrovedisRowmajorMatrix for dense data of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It will fit the model with input matrix (X) and apply the dimensionality
reduction on input matrix (X).
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)

# fitting input matrix on PCA object and perform transform 
from frovedis.mllib.decomposition import PCA
pca = PCA()
print(pca.fit_transform(mat))
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[-6.50037234  0.28016556]
 [ 1.0441383  -0.75923769]
 [ 5.45623404  0.47907213]]
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)    

# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.  
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
rmat = FrovedisRowmajorMatrix(mat)  

# Fitting PCA with pre-constructed frovedis-like inputs and perform transform  
from frovedis.mllib.decomposition import PCA
pca = PCA()
print(pca.fit_transform(rmat)) 
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[-6.50037234  0.28016556]
 [ 1.0441383  -0.75923769]
 [ 5.45623404  0.47907213]]
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
For both frovedis-like input and python input, it returns a numpy
ndarray of shape \f[B](n_samples, n_components)\f[R] and double
(float64) type values.
It contains transformed values.
.SS 4. get_params(deep = True)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]deep\f[I]\f[R]: A boolean parameter, used to get parameters
and their values for an estimator.
If True, it will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by PCA.
It is used to get parameters and their values of PCA class.
.PP
For example,
.IP
.nf
\f[C]
print(pca.get_params())  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]copy\[aq]: True, \[aq]iterated_power\[aq]: \[aq]auto\[aq], \[aq]n_components\[aq]: 2, \[aq]random_state\[aq]: None, 
\[aq]svd_solver\[aq]: \[aq]arpack\[aq], \[aq]tol\[aq]: 0.0, \[aq]whiten\[aq]: False}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 5. inverse_transform(X, y = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object of int, float or double (float64) type values.
It can also be an instance of FrovedisCRSMatrix for sparse data and
FrovedisRowmajorMatrix for dense data of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It transforms data back to its original space.
.PP
In other words, it returns an input matrix (X_original) whose transform
would be input matrix (X).
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)

# fitting input matrix on PCA object and perform transform 
from frovedis.mllib.decomposition import PCA
pca = PCA().fit(mat)
X1 = pca.transform(mat)

# inverse_transform() demo to get original input data
print(pca.inverse_transform(X1))
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[ 1.00000000e+00  0.00000000e+00  7.00000000e+00  5.77315973e-15
   1.24344979e-14]
 [ 2.00000000e+00  0.00000000e+00  3.00000000e+00  4.00000000e+00
   5.00000000e+00]
 [ 4.00000000e+00  0.00000000e+00 -7.99360578e-15  6.00000000e+00
   7.00000000e+00]]
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)    

# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.  
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
rmat = FrovedisRowmajorMatrix(mat)  

# PCA with pre-constructed frovedis-like inputs and perform transform
from frovedis.mllib.decomposition import PCA
pca = PCA().fit(rmat)
X1 = pca.transform(rmat)

# inverse_transform() demo to get original frovedis-like input data
X2 = pca.inverse_transform(X1)
X2.debug_print()
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
matrix:
num_row = 3, num_col = 5
node 0
node = 0, local_num_row = 3, local_num_col = 5, val = 1 0 7 5.77316e-15 1.24345e-14 
2 0 3 4 5 4 0 -7.99361e-15 6 7
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.IP \[bu] 2
\f[B]When X is python native input:\f[R]
.PD 0
.P
.PD
It returns a numpy ndarray of shape \f[B](n_samples, n_components)\f[R]
and double (float64) type values.
It contains original input data values.
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]When X is frovedis-like input:\f[R]
.PD 0
.P
.PD
It returns a FrovedisRowmajorMatrix instance of shape \f[B](n_samples,
n_components)\f[R] and double (float64) type values.
It contains original input data values.
.SS 6. is_fitted()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, transform() is used before training the model, then it can
prompt the user to train the pca model first.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns `True', if the model is already fitted otherwise, it returns
`False'.
.SS 7. load(path, dtype)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]path\f[B]\f[R]: A string object containing the name of the
file having model information to be loaded.
.PD 0
.P
.PD
\f[B]\f[BI]dtype\f[B]\f[R]: It is the data-type of the loaded model with
trainig data samples.
Currently, expected input data-type is either float (float32) or double
(float64).
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It loads the model from the specified file.
.PP
For example,
.IP
.nf
\f[C]
pca.load(\[dq]./out/PCAModel\[dq], dtype = np.float64)
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 8. load_binary(path, dtype)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]path\f[B]\f[R]: A string object containing the name of the
binary file having model information to be loaded.
.PD 0
.P
.PD
\f[B]\f[BI]dtype\f[B]\f[R]: It is the data-type of the loaded model with
trainig data samples.
Currently, expected input data-type is double (float64).
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It loads the model from the specified file (having binary data).
.PP
For example,
.IP
.nf
\f[C]
pca.load(\[dq]./out/PCA_BinaryModel\[dq], dtype = np.float64)  
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 9. save(path)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]path\f[B]\f[R]: A string object containing the name of the
file on which the target model is to be saved.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
On success, it writes the model information (components, mean, score,
etc.)
in the specified file.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
# To save the pca model
pca.save(\[dq]./out/PCAModel\[dq])    
\f[R]
.fi
.PP
This will save the pca model on the path `/out/PCAModel'.
It would raise exception if the directory already exists with same name.
.PP
The `PCAModel' directory has
.PP
\f[B]PCAModel\f[R]
.PD 0
.P
.PD
|\[em]-components
.PD 0
.P
.PD
|\[em]-mean
.PD 0
.P
.PD
|\[em]-score
.PD 0
.P
.PD
|\[em]-singular_values
.PD 0
.P
.PD
|\[em]-variance
.PD 0
.P
.PD
|\[em]-variance_ratio
.PP
The saved model contains the after-fitted attribute values.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 10. save_binary(path)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]path\f[B]\f[R]: A string object containing the name of the
binary file on which the target model is to be saved.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
On success, it writes the model information (components, mean, score,
etc.)
in binary format in the specified file.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
# To save the pca binary model
pca.save(\[dq]./out/PCA_BinaryModel\[dq])    
\f[R]
.fi
.PP
This will save the pca model on the path `/out/PCA_BinaryModel'.
It would raise exception if the directory already exists with same name.
.PP
The `PCA_BinaryModel' directory has
.PP
\f[B]PCA_BinaryModel\f[R]
.PD 0
.P
.PD
|\[em]-\f[B]components\f[R]
.PD 0
.P
.PD
|\[em]-mean
.PD 0
.P
.PD
|\[em]-\f[B]score\f[R]
.PD 0
.P
.PD
|\[em]-singular_values
.PD 0
.P
.PD
|\[em]-variance
.PD 0
.P
.PD
|\[em]-variance_ratio
.PP
The saved binary model contains the after-fitted attribute values.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 11. set_params(**params)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]**params\f[I]\f[R]: All the keyword arguments are passed to
this function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by PCA, used to
set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print(\[dq]get parameters before setting:\[dq]) 
print(pca.get_params())
# User just needs to provide the arguments and internally it will create a 
dictionary over the arguments given by user
pca.set_params(whiten=True)  
print(\[dq]get parameters after setting:\[dq]) 
print(pca.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
get parameters before setting:
{\[aq]copy\[aq]: True, \[aq]iterated_power\[aq]: \[aq]auto\[aq], \[aq]n_components\[aq]: 2, \[aq]random_state\[aq]: None, 
\[aq]svd_solver\[aq]: \[aq]arpack\[aq], \[aq]tol\[aq]: 0.0, \[aq]whiten\[aq]: False}
get parameters after setting:
{\[aq]copy\[aq]: True, \[aq]iterated_power\[aq]: \[aq]auto\[aq], \[aq]n_components\[aq]: 2, \[aq]random_state\[aq]: None, 
\[aq]svd_solver\[aq]: \[aq]arpack\[aq], \[aq]tol\[aq]: 0.0, \[aq]whiten\[aq]: True}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 12. transform(X, y = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object of int, float or double (float64) type values.
It can also be an instance of FrovedisCRSMatrix for sparse data and
FrovedisRowmajorMatrix for dense data of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It applies the dimensionality reduction on input matrix (X).
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)

# fitting input matrix on PCA object and perform transform 
from frovedis.mllib.decomposition import PCA
pca = PCA().fit(mat)
print(pca.transform(mat))
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[-6.50037234  0.28016556]
 [ 1.0441383  -0.75923769]
 [ 5.45623404  0.47907213]]
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample numpy dense data    
import numpy as np
mat = np.matrix([[1.0, 0.0, 7.0, 0.0, 0.0], 
                 [2.0, 0.0, 3.0, 4.0, 5.0], 
                 [4.0, 0.0, 0.0, 6.0, 7.0]], 
                dtype = np.float64)    

# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.  
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
rmat = FrovedisRowmajorMatrix(mat)  

# Fitting PCA with pre-constructed frovedis-like inputs and perform transform  
from frovedis.mllib.decomposition import PCA
pca = PCA().fit(rmat)
X1 = pca.transform(rmat)
X1.debug_print()
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
matrix:
num_row = 3, num_col = 2
node 0
node = 0, local_num_row = 3, local_num_col = 2, val = -6.50037 0.280166 1.04414 
-0.759238 5.45623 0.479072
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.IP \[bu] 2
\f[B]When X is python native input:\f[R]
.PD 0
.P
.PD
It returns a numpy ndarray of shape \f[B](n_samples, n_components)\f[R]
and double (float64) type values.
It contains the projection of input matrix (X) in the first principal
components.
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]When X is frovedis-like input:\f[R]
.PD 0
.P
.PD
It returns a FrovedisRowmajorMatrix instance of shape \f[B](n_samples,
n_components)\f[R] and double (float64) type values.
It contains the projection of input matrix (X) in the first principal
components.
.SH SEE ALSO
.IP \[bu] 2
\f[B]Introduction to FrovedisRowmajorMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisCRSMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Latent Dirichlet Allocation in frovedis\f[R]
