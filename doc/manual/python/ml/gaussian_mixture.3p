.TH "GaussianMixture" "" "" "" ""
.SH NAME
.PP
GaussianMixture \- It is a representation of a Gaussian mixture model
probability distribution.
This class allows to estimate the parameters of a Gaussian mixture
distribution.
.SH SYNOPSIS
.IP
.nf
\f[C]
class\ frovedis.mllib.mixture.gmm.GaussianMixture(n_components=1,\ covariance_type=\[aq]full\[aq],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ tol=1e\-3,\ reg_covar=1e\-6,\ max_iter=100,\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ n_init=1,\ init_params=\[aq]kmeans\[aq],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights_init=None,\ means_init=None,\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ precisions_init=None,\ random_state=None,\ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ warm_start=False,\ verbose=0,\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ verbose_interval=10)\ \ 
\f[]
.fi
.SS Public Member Functions
.PP
fit(X, y = None)
.PD 0
.P
.PD
fit_predict(X, y = None)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
predict_proba(X)
.PD 0
.P
.PD
sample(n_samples = 1)
.PD 0
.P
.PD
score(X, y = None)
.PD 0
.P
.PD
score_samples(X)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
bic(X)
.PD 0
.P
.PD
aic(X)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
A Gaussian mixture model is a probabilistic model that assumes all the
data points are generated from a mixture of a finite number of Gaussian
distributions with unknown parameters.
One can think of mixture models as generalizing k\-means clustering to
incorporate information about the covariance structure of the data as
well as the centers of the latent Gaussians.
.PP
This module provides a client\-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as Scikit\-learn GaussianMixture
interface, but it doesn't have any dependency with Scikit\-learn.
It can be used simply even if the system doesn't have Scikit\-learn
installed.
Thus, in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data nternally and the
python ML call is linked with the respective frovedis ML call to get the
job done at frovedis server.
.PP
Python side calls for GaussianMixture on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When prediction\-like request would be made on the trained model, the
python program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. GaussianMixture()
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]n_components\f[]\f[]: A positive integer parameter specifying
the number of mixture components.
(Default: 1)
.PD 0
.P
.PD
\f[I]\f[B]covariance_type\f[]\f[]: A string object parameter specifying
the type of covariance parameters to use.
.PD 0
.P
.PD
Currently, \f[B]\[aq]full\[aq]\f[] is supported in frovedis.
In \[aq]full\[aq] covariance type, each component has its own general
covariance matrix.
(Default: \[aq]full\[aq])
.PD 0
.P
.PD
\f[I]\f[B]tol\f[]\f[]: Zero or a positive double (float64) parameter
specifying the convergence tolerance.
EM (expectation\-maximization) iterations will stop when the lower bound
average gain is below this threshold.
(Default: 1e\-3)
.PD 0
.P
.PD
\f[I]\f[B]reg_covar\f[]\f[]: An unused parameter.
(Default: 1e\-6)
.PD 0
.P
.PD
\f[I]\f[B]max_iter\f[]\f[]: A positive integer parameter specifying the
number of EM (expectation\-maximization) iterations to perform.
(Default: 100)
.PD 0
.P
.PD
\f[I]\f[B]n_init\f[]\f[]: A positive integer parameter specifying the
number of initializations to perform.
(Default: 1)
.PD 0
.P
.PD
If it is None (not specified explicitly), it will be set as 1.
.PD 0
.P
.PD
\f[I]\f[B]init_params\f[]\f[]: A string object parameter specifying the
method used to initialize the weights, the means and the precisions.
(Default: \[aq]kmeans\[aq])
.PD 0
.P
.PD
Must be one of the following:
.PD 0
.P
.PD
\- \f[B]\[aq]kmeans\[aq]\f[] : responsibilities are initialized using
kmeans.
.PD 0
.P
.PD
\- \f[B]\[aq]random\[aq]\f[] : responsibilities are initialized
randomly.
.PP
\f[I]\f[B]weights_init\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[I]\f[B]means_init\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[I]\f[B]precisions_init\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[I]\f[B]random_state\f[]\f[]: An integer, float parameter or a
RandomState instance that controls the random seed given to the method
chosen to initialize the parameters.
(Default: None)
.PD 0
.P
.PD
If it is None (not specified explicitly) or a RandomState instance, it
will be set as 0.
.PD 0
.P
.PD
\f[I]\f[B]warm_start\f[]\f[]: An unused parameter.
(Default: False)
.PD 0
.P
.PD
\f[B]\f[I]verbose\f[]\f[]: An integer parameter specifying the log level
to use.
Its value is set as 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PD 0
.P
.PD
\f[I]\f[B]verbose_interval\f[]\f[]: An unused parameter.
(Default: 10)
.PP
\f[B]Attribute\f[]
.PD 0
.P
.PD
\f[I]\f[B]weights_\f[]\f[]: It is a python ndarray, containing double
(float64) typed values and has shape \f[B](n_components,)\f[].
It stores the weights of each mixture components.
.PD 0
.P
.PD
\f[I]\f[B]covariances_\f[]\f[]: It is a python ndarray, containing
double (float64) typed values.
It stores the covariance of each mixture component.
The shape depends on \f[B]covariance_type\f[]:
.PD 0
.P
.PD
\- if \f[B]\[aq]full\[aq]\f[], then the shape is \f[B](n_components,
n_features, n_features)\f[].
.PP
\f[I]\f[B]means_\f[]\f[]: It is a python ndarray, containing double
(float64) typed values and has shape \f[B](n_components,
n_features)\f[].
It stores the mean of each mixture component.
.PD 0
.P
.PD
\f[I]\f[B]converged_\f[]\f[]: A boolean value.
If True, then convergence was reached in fit(), otherwise it will be
False.
.PD 0
.P
.PD
\f[I]\f[B]n_iter_int\f[]\f[]: An integer value specifying the number of
step used by the best fit of EM to reach the convergence.
.PD 0
.P
.PD
\f[I]\f[B]lower_bound_\f[]\f[]: A float value specifying the lower bound
value on the log\-likelihood (of the training data with respect to the
model) of the best fit of EM.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It initializes a GaussianMixture object with the given parameters.
.PP
The parameters: "reg_covar", "weights_init, "means_init",
"precisions_init", "warm_start", and "verbose_interval" are simply kept
to make the interface uniform to Scikit\-learn GaussianMixture module.
They are not used anywhere within the frovedis implementation.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 2. fit(X, y = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
During training, \f[B]n_samples >= n_components\f[].
.PD 0
.P
.PD
\f[B]\f[I]y\f[]\f[]: None or any python array\-like object (any shape).
It is simply ignored in frovedis implementation, like in Scikit\-learn.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It estimates the model parameters with the EM algorithm.
.PP
The method fits the model \f[B]\[aq]n_init\[aq]\f[] times and sets the
parameters with which the model has the largest likelihood or lower
bound.
Within each trial, the method iterates between E\-step and M\-step for
\f[B]\[aq]max_iter\[aq]\f[] times until the change of likelihood or
lower bound is less than \f[B]\[aq]tol\[aq]\f[].
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ matrix\ dense\ data
#\ train_mat\ =\ np.array([[1.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 0.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 0.]])

#\ fitting\ input\ matrix\ on\ GaussianMixture\ object
from\ frovedis.mllib.mixture\ import\ GaussianMixture
gmm_model\ =\ GaussianMixture(n_components\ =\ 2)
gmm_model.fit(train_mat)\ \ 
\f[]
.fi
.PP
When native python data is provided, it is converted to frovedis\-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre\-constructed frovedis\-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ matrix\ dense\ data
#\ train_mat\ =\ np.array([[1.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 0.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 0.]])

#\ Since\ "train_mat"\ is\ numpy\ dense\ data,\ we\ have\ created\ FrovedisRowmajorMatrix.
#\ For\ scipy\ sparse\ data,\ FrovedisCRSMatrix\ should\ be\ used\ instead.
from\ frovedis.matrix.dense\ import\ FrovedisRowmajorMatrix
rmat\ =\ FrovedisRowmajorMatrix(train_mat)

#\ fitting\ GaussianMixture\ object\ with\ pre\-constructed\ input
from\ frovedis.mllib.mixture\ import\ GaussianMixture
gmm_model\ =\ GaussianMixture(n_components\ =\ 2)
gmm_model.fit(rmat)\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 3. fit_predict(X, y = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
During training, \f[B]n_samples >= n_components\f[].
.PD 0
.P
.PD
\f[B]\f[I]y\f[]\f[]: None or any python array\-like object (any shape).
It is simply ignored in frovedis implementation, like in Scikit\-learn.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It estimates the model parameters using X and predict the labels for X.
.PP
The method fits the model \f[B]\[aq]n_init\[aq]\f[] times and sets the
parameters with which the model has the largest likelihood or lower
bound.
Within each trial, the method iterates between E\-step and M\-step for
\f[B]\[aq]max_iter\[aq]\f[] times until the change of likelihood or
lower bound is less than \f[B]\[aq]tol\[aq]\f[].
After fitting, it predicts the most probable label for the input data
points.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ matrix\ dense\ data
#\ train_mat\ =\ np.array([[1.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 0.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 0.]])

#\ fitting\ input\ matrix\ on\ GaussianMixture\ object\ and\ perform\ predictions
from\ frovedis.mllib.mixture\ import\ GaussianMixture
gmm_model\ =\ GaussianMixture(n_components\ =\ 2)
print(gmm_model.fit_predict(train_mat))\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ 1\ 1\ 1]
\f[]
.fi
.PP
Like in fit() frovedis\-like input can be used to speed\-up training at
server side.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ matrix\ dense\ data
#\ train_mat\ =\ np.array([[1.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 0.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 0.]])

#\ Since\ "train_mat"\ is\ numpy\ dense\ data,\ we\ have\ created\ FrovedisRowmajorMatrix.
#\ For\ scipy\ sparse\ data,\ FrovedisCRSMatrix\ should\ be\ used\ instead.
from\ frovedis.matrix.dense\ import\ FrovedisRowmajorMatrix
rmat\ =\ FrovedisRowmajorMatrix(train_mat)

#\ fitting\ GaussianMixture\ object\ with\ pre\-constructed\ input\ and\ perform\ predictions
from\ frovedis.mllib.mixture\ import\ GaussianMixture
gmm_model\ =\ GaussianMixture(n_components\ =\ 2)
print(gmm_model.fit_predict(rmat))\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ 1\ 1\ 1]
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of int64 type values containing the components
labels.
It has a shape \f[B](n_samples,)\f[].
.SS 4. predict(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PP
It predict the labels for the data samples in X using trained model.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ matrix\ dense\ data
#\ train_mat\ =\ np.array([[1.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 0.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 0.]])

#\ predicting\ on\ GaussianMixture\ model
from\ frovedis.mllib.mixture\ import\ GaussianMixture
gmm_model\ =\ GaussianMixture(n_components\ =\ 2).fit(train_mat)
print(gmm_model.predict(train_mat))\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ 1\ 1\ 1]
\f[]
.fi
.PP
Like in fit(), frovedis\-like input can be used to speed\-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ matrix\ dense\ data
#\ train_mat\ =\ np.array([[1.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1.,\ 0.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 2.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 4.],\ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [10.,\ 0.]])

#\ Since\ "train_mat"\ is\ numpy\ dense\ data,\ we\ have\ created\ FrovedisRowmajorMatrix.
from\ frovedis.matrix.dense\ import\ FrovedisRowmajorMatrix
rmat\ =\ FrovedisRowmajorMatrix(train_mat)

#\ predicting\ on\ GaussianMixture\ model\ using\ pre\-constructed\ input
from\ frovedis.mllib.mixture\ import\ GaussianMixture
gmm_model\ =\ GaussianMixture(n_components\ =\ 2).fit(rmat)
print(gmm_model.predict(rmat))\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ 1\ 1\ 1]
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of int64 type values containing the components
labels.
It has a shape \f[B](n_samples,)\f[].
.SS 5. sample(n_samples = 1)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]n_samples\f[]\f[]: A positive integer value that specifies the
number of samples to generate.
(Default: 1)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Currently this method is not supported for GaussianMixture in frovedis.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply raises a NotImplementedError.
.SS 6. score(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It computes the per\-sample average log\-likelihood of the given data X.
.PP
For example,
.IP
.nf
\f[C]
#\ calculate\ log\-likelihood\ on\ given\ test\ data\ X
gmm_model.score(train_mat)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
3.386
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a score of double (float64) type.
.SS 7. score_samples(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It computes the log\-likelihood of each sample.
.PP
For example,
.IP
.nf
\f[C]
gmm_model.score_samples(train_mat)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[3.88631622\ 3.1363165\ \ 3.1363165\ \ 3.88631622\ 3.1363165\ \ 3.1363165\ ]
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of double (float64) type containing
log\-likelihood of each sample in \[aq]X\[aq] under the current model.
It has a shape \f[B](n_samples,)\f[].
.SS 8. get_params(deep = True)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]deep\f[]\f[]: A boolean parameter, used to get parameters and
their values for an estimator.
If True, will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
GaussianMixture.
It is used to get parameters and their values of GaussianMixture class.
.PP
For example,
.IP
.nf
\f[C]
print(gmm_model.get_params())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]covariance_type\[aq]:\ \[aq]full\[aq],\ \[aq]init_params\[aq]:\ \[aq]kmeans\[aq],\ \[aq]max_iter\[aq]:\ 100,\ \[aq]means_init\[aq]:\ None,\ 
\[aq]n_components\[aq]:\ 2,\ \[aq]n_init\[aq]:\ 1,\ \[aq]precisions_init\[aq]:\ None,\ \[aq]random_state\[aq]:\ None,\ 
\[aq]reg_covar\[aq]:\ None,\ \[aq]tol\[aq]:\ 0.001,\ \[aq]verbose\[aq]:\ 0,\ \[aq]verbose_interval\[aq]:\ None,\ \[aq]warm_start\[aq]:\ None,\ 
\[aq]weights_init\[aq]:\ None}
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 9. set_params(**params)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]**params\f[]\f[]: All the keyword arguments are passed this
function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
GaussianMixture, used to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print("get\ parameters\ before\ setting:")
print(gmm_model.get_params())
#\ User\ just\ needs\ to\ provide\ the\ arguments\ and\ internally\ it\ will\ create\ a\ 
dictionary\ over\ the\ arguments\ given\ by\ user
gmm_model.set_params(n_components\ =\ 4)
print("get\ parameters\ after\ setting:")
print(gmm_model.get_params())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
get\ parameters\ before\ setting:
{\[aq]covariance_type\[aq]:\ \[aq]full\[aq],\ \[aq]init_params\[aq]:\ \[aq]kmeans\[aq],\ \[aq]max_iter\[aq]:\ 100,\ \[aq]means_init\[aq]:\ None,\ 
\[aq]n_components\[aq]:\ 2,\ \[aq]n_init\[aq]:\ 1,\ \[aq]precisions_init\[aq]:\ None,\ \[aq]random_state\[aq]:\ None,\ 
\[aq]reg_covar\[aq]:\ None,\ \[aq]tol\[aq]:\ 0.001,\ \[aq]verbose\[aq]:\ 0,\ \[aq]verbose_interval\[aq]:\ None,\ \[aq]warm_start\[aq]:\ None,\ 
\[aq]weights_init\[aq]:\ None}
get\ parameters\ after\ setting:
{\[aq]covariance_type\[aq]:\ \[aq]full\[aq],\ \[aq]init_params\[aq]:\ \[aq]kmeans\[aq],\ \[aq]max_iter\[aq]:\ 100,\ \[aq]means_init\[aq]:\ None,\ 
\[aq]n_components\[aq]:\ 4,\ \[aq]n_init\[aq]:\ 1,\ \[aq]precisions_init\[aq]:\ None,\ \[aq]random_state\[aq]:\ None,\ 
\[aq]reg_covar\[aq]:\ None,\ \[aq]tol\[aq]:\ 0.001,\ \[aq]verbose\[aq]:\ 0,\ \[aq]verbose_interval\[aq]:\ None,\ \[aq]warm_start\[aq]:\ None,\ 
\[aq]weights_init\[aq]:\ None}
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 10. load(fname, dtype = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]fname\f[]\f[]: A string object containing the name of the file
having model information to be loaded.
.PD 0
.P
.PD
\f[I]\f[B]dtype\f[]\f[]: A data\-type is inferred from the input data.
Currently, expected input data\-type is either float or double
(float64).
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It loads the model from the specified file(having little\-endian binary
data).
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ the\ same\ model
gmm_model.load("./out/MyGmmModel",dtype\ =\ np.float64)
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 11. save(fname)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]fname\f[]\f[]: A string object containing the name of the file
on which the target model is to be saved.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
On success, it writes the model information (metadata and model) in the
specified file as little\-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
#\ saving\ the\ model
gmm_model.save("./out/MyGmmModel")
\f[]
.fi
.PP
This will save the random forest classifier model on the path
"/out/MyGmmModel".
It would raise exception if the directory already exists with same name.
.PP
The MyGmmModel contains below directory structure:
.PP
\f[B]MyGmmModel\f[]
.PD 0
.P
.PD
|\-\-\-\-\-\-metadata
.PD 0
.P
.PD
|\-\-\-\-\-\-model
.PP
\[aq]metadata\[aq] represents the detail about n_components, n_features,
converged_, n_iter_, lower_bound_, model_kind and datatype of training
vector.
.PD 0
.P
.PD
Here, the \[aq]model\[aq] file contains information about gaussian
mixture model in binary format.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 12. bic(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It is the Bayesian information criterion for the current model on the
input X.
.PP
For example,
.IP
.nf
\f[C]
gmm_model.bic(train_mat)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
\-20.926
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a bayesian information criterion of double (float64) type.
.SS 13. aic(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It is the Akaike information criterion for the current model on the
input X.
.PP
For example,
.IP
.nf
\f[C]
gmm_model.aic(train_mat)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
\-18.636
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns an akaike information criterion of double (float64) type.
.SS 14. debug_print()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It shows the target model information on the server side user terminal.
It is mainly used for debugging purpose.
.PP
For example,
.IP
.nf
\f[C]
gmm_model.debug_print()
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
Gaussian\ Mixture\ Model:
Means:
node\ =\ 0,\ local_num_row\ =\ 2,\ local_num_col\ =\ 2,\ val\ =\ 1\ 2\ 10\ 2

Weights:
node\ =\ 0,\ local_num_row\ =\ 2,\ local_num_col\ =\ 1,\ val\ =\ 0.5\ 0.5

Covariances:
node\ =\ 0,\ local_num_row\ =\ 2,\ local_num_col\ =\ 4,\ val\ =\ 0\ 0\ 0\ 2.66667\ 0\ 0\ 0\ 2.66667
\f[]
.fi
.PP
It displays the information on the trained model such as means, weights,
covariances which is currently present on the server.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 15. release()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to release the in\-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
gmm_model.release()
\f[]
.fi
.PP
This will reset the after\-fit populated attributes (like weights_,
means_, etc.) to None, along with releasing server side memory.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 16. is_fitted()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, predict() is used before training the model, then it can prompt
the user to train the model first.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns \[aq]True\[aq], if the model is already fitted otherwise, it
returns \[aq]False\[aq].
.SS SEE ALSO
.PP
rowmajor_matrix, crs_matrix, kmeans
