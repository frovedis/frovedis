.\" Automatically generated by Pandoc 2.17.1.1
.\"
.\" Define V font for inline verbatim, using C font in formats
.\" that render this, and otherwise B font.
.ie "\f[CB]x\f[]"x" \{\
. ftr V B
. ftr VI BI
. ftr VB B
. ftr VBI BI
.\}
.el \{\
. ftr V CR
. ftr VI CI
. ftr VB CB
. ftr VBI CBI
.\}
.TH "FactorizationMachineRegressor" "" "" "" ""
.hy
.SH NAME
.PP
FactorizationMachineRegressor - A factorization machine is a
general-purpose supervised learning algorithm that can be used for
regression tasks.
It is an extension of a linear model that is designed to capture
interactions between features within high dimensional sparse datasets.
.SH SYNOPSIS
.IP
.nf
\f[C]
class frovedis.mllib.fm.FactorizationMachineRegressor(iteration=100, init_stdev=0.1,  
                                                      init_learn_rate=0.01, optimizer=\[lq]SGD\[rq],  
                                                      dim=(True,True, 8), reg=(0, 0, 0),  
                                                      batch_size_pernode=100, verbose=0)  
\f[R]
.fi
.SS Public Member Functions
.PP
fit(X, y, sample_weight = None)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
score(X, y, sample_weight = None)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
The FactorizationMachineRegressor (fmr) is a general predictor like SVMs
but is also able to estimate reliable parameters under very high
sparsity.
The factorization machine models all nested variable interactions
(comparable to a polynomial kernel in SVM), but uses a factorized
parameterization instead of a dense parametrization like in SVMs.
We show that the model equation of fmrs can be computed in linear time
and that it depends only on a linear number of parameters.
This allows direct optimization and storage of model parameters without
the need of storing any training data (e.g.\ support vectors) for
prediction.
.PP
This module provides a client-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as libFM.
libFM is a software implementation for factorization machines that
features stochastic gradient descent (SGD) and alternating least squares
(ALS) optimization as well as Bayesian inference using Markov Chain
Monte Carlo (MCMC).
In this implementation, a python client can interact with a frovedis
server sending the required python data for training at frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for FactorizationMachineRegressor on the frovedis
server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When predict-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. FactorizationMachineRegressor()
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]iteration\f[B]\f[R]: A positive integer parameter, specifying
the maximum number of iteration count.
(Default: 100)
.PD 0
.P
.PD
\f[B]\f[BI]init_stdev\f[B]\f[R]: A positive double parameter specifying
the standard deviation which is used to initialize the model parameter
of 2-way factors (Default: 0.1)
.PD 0
.P
.PD
\f[B]\f[BI]init_learn_rate\f[B]\f[R]: A double parameter containing the
learning rate for SGD optimizer.
(Default: 0.01)
.PD 0
.P
.PD
It should be in range from 0.00001 to 1.0.
.PD 0
.P
.PD
\f[B]\f[BI]optimizer\f[B]\f[R]: A string object parameter that specifies
which algorithms minimize or maximize a Loss function E(x) using its
Gradient values with respect to the parameters.
(Default: `SGD')
.PD 0
.P
.PD
Only `SGD' is supported.
.PD 0
.P
.PD
\f[B]\f[BI]dim\f[B]\f[R]: A tuple that specifies three important
parameters with default values- (True, True,8):
.PD 0
.P
.PD
- \f[B]\f[BI]global_bias\f[B]\f[R]: A boolean value that represents a
switch to use bias.
Currently, this parameter is not used in Frovedis implementation.
.PD 0
.P
.PD
- \f[B]\f[BI]dim_one_interactions\f[B]\f[R] : A boolean value that
represents a switch to use 1-way interaction.
.PD 0
.P
.PD
- \f[B]\f[BI]dim_factors_no\f[B]\f[R] : A positive integer that
represents the dimension of 2-way interaction or number of factors that
are used for pairwise interactions.
.PP
When any of the three is None (not specified explicitly), then user
experiences an Error.
.PD 0
.P
.PD
\f[B]\f[BI]reg\f[B]\f[R]: An tuple of values that specifies three
important parameters with default values- (Default: (0, 0, 0))
.PD 0
.P
.PD
- \f[B]\f[BI]regularization_intercept\f[B]\f[R] : A positive integer
that represents the regularization parameters of intercept or bias
regularization.
.PD 0
.P
.PD
- \f[B]\f[BI]regularization_one_interactions\f[B]\f[R] : A positive
integer that represents the switch to use 1-way regularization.
.PD 0
.P
.PD
- \f[B]\f[BI]regularization_factors_no\f[B]\f[R] : A positive integer
that represents the dimension of 2-way interaction or number of factors
that are used for pairwise regularization.
.PP
When any of the three is None (not specified explicitly), then user
experiences an Error.
.PD 0
.P
.PD
\f[B]\f[BI]batch_size_pernode\f[B]\f[R]: A positive integer parameter
specifies the size of minibatch processed by one node.
(Default: 100)
.PD 0
.P
.PD
\f[B]\f[BI]verbose\f[B]\f[R]: An integer parameter specifying the log
level to use.
Its value is set as 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It initializes a FactorizationMachineRegressor object with the given
parameters.
.PD 0
.P
.PD
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 2. fit(X, y, sample_weight=None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A scipy sparse matrix or an instance of
FrovedisCRSMatrix of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]y\f[I]\f[R]: Any python array-like object or an instance of
FrovedisDvector containing the target values.
It has shape \f[B](n_samples,)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]sample_weight\f[B]\f[R]: A python ndarray containing the
intended weights for each input samples and it should be the shape of
\f[B](n_samples,)\f[R].
(Default: None)
.PD 0
.P
.PD
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It accepts the training matrix (X) with labels (y) and trains a
FactorizationMachineRegressor model.
.PP
For example,
.IP
.nf
\f[C]
# loading sample data   
row = np.array([0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5])
col = np.array([0, 1, 4, 0, 1, 2, 4, 1, 2, 3, 2,3,4,5, 0, 1, 3, 4, 3, 5])
data = np.asarray([ 2.0, 1.0,1.0, 1.0, 3.0,1.0, 1.0, 1.0, 2.0,1.0, 1.0, 3.0,
                    1.0,1.0,1.0, 1.0, 1.0, 3.0,1.0, 1.0])
csr = csr_matrix((data, (row, col)), shape = (6, 6))
lbl = [10.0, 10.0, 10.0, 20.0, 10.0, 20.0]

# fitting input data on FactorizationMachineRegressor object
from frovedis.mllib.fm import FactorizationMachineRegressor
fmr = FactorizationMachineRegressor()
fmr.fit(csr, lbl)
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading sample data
row = np.array([0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5])
col = np.array([0, 1, 4, 0, 1, 2, 4, 1, 2, 3, 2,3,4,5, 0, 1, 3, 4, 3, 5])
data = np.asarray([ 2.0, 1.0,1.0, 1.0, 3.0,1.0, 1.0, 1.0, 2.0,1.0, 1.0, 3.0,
                    1.0,1.0,1.0, 1.0, 1.0, 3.0,1.0, 1.0])
csr = csr_matrix((data, (row, col)), shape = (6, 6))
lbl = [10.0, 10.0, 10.0, 20.0, 10.0, 20.0]

# Since \[dq]csr\[dq] is scipy sparse data, we have created FrovedisCRSMatrix. 
from frovedis.matrix.crs import FrovedisCRSMatrix
from frovedis.matrix.dvector import FrovedisDvector
cmat = FrovedisCRSMatrix(csr)
dlbl = FrovedisDvector(lbl)

# fitting input data on FactorizationMachineRegressor object
from frovedis.mllib.fm import FactorizationMachineRegressor
fmr = FactorizationMachineRegressor()
fmr.fit(cmat, dlbl)
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 3. predict(X)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A scipy sparse matrix or an instance of
FrovedisCRSMatrix of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
# predicting on FactorizationMachineRegressor model
fmr.predict(csr)
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[10.00277618 20.6134937  13.81870647 26.75876098 33.13530746  3.03828379]
\f[R]
.fi
.PP
Like in fit(), frovedis-like input can be used to speed-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
# Since \[dq]csr\[dq] is scipy sparse data, we have created FrovedisCRSMatrix. 
from frovedis.matrix.crs import FrovedisCRSMatrix
cmat = FrovedisCRSMatrix(csr)
 
# predicting on FactorizationMachineRegressor model using pre-constructed input
fmr.predict(cmat)
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[10.00277618 20.6134937  13.81870647 26.75876098 33.13530746  3.03828379]
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a numpy array of double (float64) type containing the
predicted outputs.
It is of shape \f[B](n_samples,)\f[R].
.SS 4. load(fname, dtype = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]fname\f[B]\f[R]: A string object containing the name of the
file having model information to be loaded.
.PD 0
.P
.PD
\f[B]\f[BI]dtype\f[B]\f[R]: A data-type is inferred from the input data.
Currently, expected input data-type is either float or double (float64).
(Default: None)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
Currently, this method is not supported for
FactorizationMachineRegressor.
It is simply kept in FactorizationMachineRegressor module to maintain
uniform interface like other estimators in frovedis.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply raises an AttributeError.
.SS 5. score(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A scipy sparse matrix or an instance of
FrovedisCRSMatrix of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]y\f[I]\f[R]: Any python array-like object containing the
target values.
It has shape \f[B](n_samples,)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]sample_weight\f[B]\f[R]: A python ndarray containing the
intended weights for each input samples and it should be the shape of
\f[B](n_samples,)\f[R].
(Default: None)
.PD 0
.P
.PD
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
Calculate the root mean square value on the given test data and labels
i.e.\ R2(r-squared) of self.predict(X) wrt.
y.
.PP
The coefficient `R2' is defined as (1 - (u/v)),
.PD 0
.P
.PD
where `u' is the residual sum of squares ((y_true - y_pred) ** 2).sum()
and
.PD 0
.P
.PD
`v' is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().
.PP
The best possible score is 1.0 and it can be negative (because the model
can be arbitrarily worse).
A constant model that always predicts the expected value of y,
disregarding the input features, would get a R2 score of 0.0.
.PP
For example,
.IP
.nf
\f[C]
fmr.score(csr, lbl)
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
-0.10
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns an accuracy score of double (float64) type.
.SS 6. save(fname)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]fname\f[B]\f[R]: A string object containing the name of the
file on which the target model is to be saved.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
On success, it writes the model information(metadata and model) in the
specified file as little-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
# To save the FactorizationMachineRegressor model
fmr.save(\[dq]./out/FMRModel\[dq])
\f[R]
.fi
.PP
The FMRModel contains below directory structure:
.PD 0
.P
.PD
\f[B]FMRModel\f[R]
.PD 0
.P
.PD
|\[em]\[em]metadata
.PD 0
.P
.PD
|\[em]\[em]model
.PP
`metadata' represents the detail about model_kind and datatype of
training vector.
.PD 0
.P
.PD
Here, the model file contains information about trained model in binary
format.
.PP
This will save the FactorizationMachineRegressor model on the path
`/out/FMRModel'.
It would raise exception if the directory already exists with same name.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 7. get_params(deep = True)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]deep\f[I]\f[R]: A boolean parameter, used to get parameters
and their values for an estimator.
If True, it will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
FactorizationMachineRegressor.
It is used to get parameters and their values of
FactorizationMachineRegressor class.
.PP
For example,
.IP
.nf
\f[C]
print(fmr.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]batch_size_pernode\[aq]: 100, \[aq]dim\[aq]: (True, True, 8), \[aq]init_learn_rate\[aq]: 0.01, 
\[aq]init_stdev\[aq]: 0.1, \[aq]iteration\[aq]: 100, \[aq]optimizer\[aq]: \[aq]SGD\[aq], \[aq]reg\[aq]: (False, False, 0), 
\[aq]verbose\[aq]: 0}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 8. set_params(**params)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]**params\f[I]\f[R]: All the keyword arguments are passed this
function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
FactorizationMachineRegressor, used to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print(\[dq]Get parameters before setting:\[dq]) 
print(fmr.get_params())
# User just needs to provide the arguments and internally it will create a 
dictionary over the arguments given by user
fmr.set_params(iteration=200) 
print(\[dq]Get parameters after setting:\[dq]) 
print(fmr.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
Get parameters before setting: {\[aq]batch_size_pernode\[aq]: 100, \[aq]dim\[aq]: (True, True, 8), 
\[aq]init_learn_rate\[aq]: 0.01, \[aq]init_stdev\[aq]: 0.1, \[aq]iteration\[aq]: 100, \[aq]optimizer\[aq]: \[aq]SGD\[aq],
\[aq]reg\[aq]: (False, False, 0), \[aq]verbose\[aq]: 0}
Get parameters before setting: {\[aq]batch_size_pernode\[aq]: 100, \[aq]dim\[aq]: (True, True, 8), 
\[aq]init_learn_rate\[aq]: 0.01, \[aq]init_stdev\[aq]: 0.1, \[aq]iteration\[aq]: 200, \[aq]optimizer\[aq]: \[aq]SGD\[aq], 
\[aq]reg\[aq]: (0, 0, 0), \[aq]verbose\[aq]: 0}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 9. debug_print()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
Currently, this method is not supported for
FactorizationMachineRegressor.
It is simply kept in FactorizationMachineRegressor module to maintain
uniform interface like other estimators in frovedis.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply raises an AttributeError.
.SS 10. release()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to release the in-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
fmr.release()
\f[R]
.fi
.PP
This will reset the after-fit populated attributes to None, along with
releasing server side memory.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 11. is_fitted()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, predict() is used before training the model, then it can prompt
the user to train the model first.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns `True', if the model is already fitted otherwise, it returns
`False'.
.SH SEE ALSO
.IP \[bu] 2
\f[B]Introduction to FrovedisCRSMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisDvector\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Factorization Machine Classifier in Frovedis\f[R]
