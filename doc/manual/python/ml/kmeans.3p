.\" Automatically generated by Pandoc 2.17.1.1
.\"
.\" Define V font for inline verbatim, using C font in formats
.\" that render this, and otherwise B font.
.ie "\f[CB]x\f[]"x" \{\
. ftr V B
. ftr VI BI
. ftr VB B
. ftr VBI BI
.\}
.el \{\
. ftr V CR
. ftr VI CI
. ftr VB CB
. ftr VBI CBI
.\}
.TH "KMeans Clustering" "" "" "" ""
.hy
.SH NAME
.PP
KMeans - is a clustering algorithm commonly used in EDA (exploratory
data analysis).
.SH SYNOPSIS
.IP
.nf
\f[C]
class frovedis.mllib.cluster.KMeans(n_clusters=8, init=\[aq]random\[aq], n_init=10, max_iter=300,  
                                    tol=1e-4, precompute_distances=\[aq]auto\[aq], verbose=0,   
                                    random_state=None, copy_x=True, n_jobs=1,  
                                    algorithm=\[aq]auto\[aq], use_shrink=False)  
\f[R]
.fi
.SS Public Member Functions
.PP
fit(X, y = None, sample_weight = None)
.PD 0
.P
.PD
fit_predict(X, y = None, sample_weight = None)
.PD 0
.P
.PD
fit_transform(X, y = None, sample_weight = None)
.PD 0
.P
.PD
transform(X)
.PD 0
.P
.PD
predict(X, sample_weight = None)
.PD 0
.P
.PD
score(X, y = None, sample_weight = None)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
Clustering is an unsupervised learning problem whereby we aim to group
subsets of entities with one another based on some notion of similarity.
Kmeans is one of the most commonly used clustering algorithms that
clusters the data points into a predefined number of clusters.
.PP
Under unsupervised learning, there are two clustering methods- `k-means'
and `k-means++'.
The main difference between these two lies in the selection of the
centroids (we assume centroid is the center of the cluster) around which
the clustering takes place.
.PP
\f[B]Frovedis supports only k-means clustering method (i.e.\ init
=`random')\f[R] which will randomly initialize the data points called
centroid.
Further, each data point is clustered to its nearest centroid and after
every iteration the centroid is updated for each cluster.
This cycle continues for a given number of repetitions and after that we
have our final clusters.
.PP
This module provides a client-server implementation, where the client
application is a normal python program.
Frovedis is almost same as Scikit-learn clustering module providing
kmeans support, but it doesn\[cq]t have any dependency with
Scikit-learn.
It can be used simply even if the system doesn\[cq]t have Scikit-learn
installed.
Thus, in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for Kmeans on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When prediction-like request would be made on the trained model, the
python program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. KMeans()
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]n_clusters\f[I]\f[R]: An integer parameter specifying the
number of clusters.
The number of clusters should be greater than zero and less than
n_samples.
(Default: 8)
.PD 0
.P
.PD
When it is None (specified explicitly), then it will be set as min(8,
n_samples).
.PD 0
.P
.PD
\f[I]\f[BI]init\f[I]\f[R]: A string object parameter specifies the
method of initialization.
(Default: `random')
.PD 0
.P
.PD
Unlike Scikit-learn, currently it only supports `random' initialization.
.PD 0
.P
.PD
\f[I]\f[BI]n_init\f[I]\f[R]: A positive integer specifying the number of
times the kmeans algorithm will be run with different centroid seeds.
(Default: 10)
.PD 0
.P
.PD
When it is None (specified explicitly), then it will be set as default
10.
.PD 0
.P
.PD
\f[I]\f[BI]max_iter\f[I]\f[R]: A positive integer parameter specifying
the maximum iteration count.
(Default: 300)
.PD 0
.P
.PD
\f[I]\f[BI]tol\f[I]\f[R]: Zero or a positive double (float64) parameter
specifying the convergence tolerance.
(Default: 1e-4)
.PD 0
.P
.PD
\f[I]\f[BI]precompute_distances\f[I]\f[R]: A string object parameter.
(unused)
.PD 0
.P
.PD
\f[I]\f[BI]verbose\f[I]\f[R]: An integer parameter specifying the log
level to use.
Its value is set as 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PD 0
.P
.PD
\f[I]\f[BI]random_state\f[I]\f[R]: A zero or positive integer parameter.
When it is None (not specified explicitly), it will be set as 0.
(unused)
.PD 0
.P
.PD
\f[I]\f[BI]copy_x\f[I]\f[R]: A boolean parameter.
(unused)
.PD 0
.P
.PD
\f[I]\f[BI]n_jobs\f[I]\f[R]: An integer parameter.
(unused)
.PD 0
.P
.PD
\f[I]\f[BI]algorithm\f[I]\f[R]: A string object parameter, specifies the
kmeans algorithm to use.
(Default: auto)
.PD 0
.P
.PD
When it is `auto', it will be set as `full'.
Unlike Scikit-learn, currently it supports only `full'.
.PD 0
.P
.PD
\f[I]\f[BI]use_shrink\f[I]\f[R]: A boolean parameter applicable only for
\[lq]sparse\[rq] input (X).
When set to True for sparse input, it can improve training performance
by reducing communication overhead across participating processes.
(Default: False)
.PP
\f[B]Attribute\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]cluster_centers_\f[I]\f[R]: It is a python ndarray,
containing float or double (float64) typed values and has shape
\f[B](n_clusters, n_features)\f[R].
These are the coordinates of cluster centers.
.PD 0
.P
.PD
\f[I]\f[BI]labels_\f[I]\f[R]: A python ndarray of int64 values and has
shape \f[B](n_clusters,)\f[R].
It contains predicted cluster labels for each point.
.PD 0
.P
.PD
\f[I]\f[BI]inertia_\f[I]\f[R]: A float parameter specifies the sum of
squared distances of samples to their closest cluster center, weighted
by the sample weights if provided.
.PD 0
.P
.PD
\f[I]\f[BI]n_iter_\f[I]\f[R]: An integer parameter specifies the number
of iterations to run.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It initializes a Kmeans object with the given parameters.
.PP
The parameters: \[lq]precompute_distances\[rq], \[lq]random_state\[rq],
\[lq]copy_x\[rq] and \[lq]n_jobs\[rq] are simply kept to make the
interface uniform to Scikit-learn cluster module.
They are not used anywhere within frovedis implementation.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 2. fit(X, y = None, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]X\f[I]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data of float or double
(float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]y\f[I]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PD 0
.P
.PD
\f[I]\f[BI]sample_weight\f[I]\f[R]: An unused parameter whose default
value is None.
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It clusters the given data points (X) into a predefined number of
clusters (n_clusters).
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
train_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# fitting input matrix on kmeans object
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1).fit(train_mat)   
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
train_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# Since \[dq]train_mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.
# For scipy sparse data, FrovedisCRSMatrix should be used instead.   
from frovedis.matrix.dense import FrovedisRowmajorMatrix
rmat = FrovedisRowmajorMatrix(train_mat)

# KMeans with pre-constructed frovedis-like inputs
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1).fit(rmat)
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 3. fit_predict(X, y = None, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]X\f[I]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data of float or double
(float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]y\f[I]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PD 0
.P
.PD
\f[I]\f[BI]sample_weight\f[I]\f[R]: An unused parameter whose default
value is None.
It is simply ignored in frovedis implementation.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It clusters the given data points (X) into a predefined number of
clusters (n_clusters) and predicts the cluster index for each sample.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
train_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# fitting input matrix on KMeans object
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1)
print(kmeans.fit_predict(train_mat))    
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[0 0 1 1 1]
\f[R]
.fi
.PP
Like in fit() frovedis-like input can be used to speed-up training at
server side.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data    
train_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# Since \[dq]train_mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.
# For scipy sparse data, FrovedisCRSMatrix should be used instead.
from frovedis.matrix.dense import FrovedisRowmajorMatrix
rmat = FrovedisRowmajorMatrix(train_mat)

# using pre-constructed input matrix
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1)
print(kmeans.fit_predict(rmat))
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[0 0 1 1 1]
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a numpy array of int64 type containing the cluster labels.
It has a shape \f[B](n_samples,)\f[R].
.SS 4. fit_transform(X, y = None, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]X\f[I]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data of float or double
(float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]y\f[I]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PD 0
.P
.PD
\f[I]\f[BI]sample_weight\f[I]\f[R]: An unused parameter whose default
value is None and simply ignored in frovedis implementation.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It computes clustering and transforms training data (X) to
cluster-distance space.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
train_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# fitting input matrix on KMeans object
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1)
print(kmeans.fit_transform(train_mat))
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[ 0.08660254 15.58845727]
[ 0.08660254 15.41525219]
[15.32864965  0.17320508]
[15.50185473  0.        ]
[15.67505981  0.17320508]]
\f[R]
.fi
.PP
If training data (X) is a numpy array or a scipy sparse matrix, it will
return a new numpy dense array.
.PP
Like in fit() frovedis-like input can be used to speed-up training at
server side.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
train_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# Since \[dq]train_mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.
# For scipy sparse data, FrovedisCRSMatrix should be used instead.
from frovedis.matrix.dense import FrovedisRowmajorMatrix
rmat = FrovedisRowmajorMatrix(train_mat)

# using pre-constructed input matrix
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1)
# it returns a FrovedisRowmajorMatrix object
kmeans.fit_transform(rmat)
\f[R]
.fi
.PP
If training data (X) is a frovedis-like input, it will return a
FrovedisRowmajorMatrix object.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
- \f[B]When training data is native-python data\f[R]:
.PD 0
.P
.PD
Then the output will be a numpy array containing the transformed matrix.
.PD 0
.P
.PD
- \f[B]When training data is frovedis-like data\f[R]:
.PD 0
.P
.PD
Then the output will be a FrovedisRowmajorMatrix.
.PP
In both cases output would be of float or double (float64) type
(depending upon input dtype) and of shape \f[B](n_samples,
n_clusters)\f[R].
.PP
Note that even if training data (X) is sparse, the output would
typically be dense.
.SS 5. transform(X)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]X\f[I]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data of float or double
(float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It transforms the test data (X) to a cluster-distance space.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
test_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# fitting input matrix on kmeans object
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1).fit(test_mat)
print(kmeans.transform(test_mat))    
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[ 0.08660254 15.58845727]
[ 0.08660254 15.41525219]
[15.32864965  0.17320508]
[15.50185473  0.        ]
[15.67505981  0.17320508]]
\f[R]
.fi
.PP
If test data (X) is a numpy array or a scipy sparse matrix, it will
return a new numpy dense array.
.PP
Like in fit() frovedis-like input can be used to speed-up training the
test data at server side.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
test_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# Since \[dq]test_mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.
# For scipy sparse data, FrovedisCRSMatrix should be used instead.   
from frovedis.matrix.dense import FrovedisRowmajorMatrix
tr_mat = FrovedisRowmajorMatrix(test_mat)

# using pre-constructed input matrix
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1).fit(tr_mat)
kmeans.transform(tr_mat)
\f[R]
.fi
.PP
If test data (X) is a frovedis-like input, it will return
FrovedisRowmajorMatrix object.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
- \f[B]If native-python data is input:\f[R]
.PD 0
.P
.PD
Then it returns a numpy array containing the transformed matrix.
.PD 0
.P
.PD
- \f[B]If frovedis-like data is input:\f[R]
.PD 0
.P
.PD
Then it returns a FrovedisRowmajorMatrix.
.PP
In both cases output would be of float or double (float64) type
(depending upon input dtype) and of shape \f[B](n_samples,
n_clusters)\f[R].
.PP
Note that even if test data (X) is sparse, the output would typically be
dense.
.SS 6. predict(X, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]X\f[I]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data of float or double
(float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]sample_weight\f[I]\f[R]: None or any python array-like object
containing the intended weights for each input samples.
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It accepts the test data points (X) and returns the closest cluster each
sample in X belongs to.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
test_mat = np.loadtxt(\[dq]sample_data.txt\[dq])
    
# fitting input matrix on KMeans object
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1).fit(test_mat)
print(kmeans.predict(test_mat))    
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[0 0 1 1 1]
\f[R]
.fi
.PP
Like in fit() frovedis-like input can be used to speed-up prediction on
the test data at server side.
.PP
For example,
.IP
.nf
\f[C]
# loading sample matrix data
test_mat = np.loadtxt(\[dq]sample_data.txt\[dq])

# Since \[dq]test_mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.
# For scipy sparse data, FrovedisCRSMatrix should be used instead.
from frovedis.matrix.dense import FrovedisRowmajorMatrix
tr_mat = FrovedisRowmajorMatrix(test_mat)

# using pre-constructed input matrix
from frovedis.mllib.cluster import KMeans
kmeans = KMeans(n_clusters = 2, n_init = 1).fit(tr_mat)
print(kmeans.predict(tr_mat))
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[0 0 1 1 1]
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a numpy array of int32 type containing the centroid values.
It has a shape \f[B](n_samples,)\f[R].
.SS 7. score(X, y = None, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]X\f[I]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data of float or double
(float64) type.
It has shape \f[B](n_samples, n_features)\f[R].
.PD 0
.P
.PD
\f[I]\f[BI]y\f[I]\f[R]: None or any python array-like object (any
shape).
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PD 0
.P
.PD
\f[I]\f[BI]sample_weight\f[I]\f[R]: None or any python array-like object
containing the intended weights for each input samples.
It is simply ignored in frovedis implementation, like in Scikit-learn.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It is calculated as \[lq]-1.0 * inertia\[rq], which an indication of how
far the points are from the centroids.
Bad scores will return a large negative number, whereas good scores
return a value close to zero.
.PP
For example,
.IP
.nf
\f[C]
kmeans.score(test_mat)
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
-0.07499999552965164
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a score of float type.
.SS 8. load(fname, dtype = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]fname\f[I]\f[R]: A string object containing the name of the
file having model information to be loaded.
.PD 0
.P
.PD
\f[I]\f[BI]dtype\f[I]\f[R]: A data-type is inferred from the input data.
Currently, expected input data-type is either float or double (float64).
(Default: None)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It loads the model from the specified file(having little-endian binary
data).
.PP
For example,
.IP
.nf
\f[C]
# loading the same model
kmeans.load(\[dq]./out/MyKMeansModel\[dq],dtype=np.float64)
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] instance.
.SS 9. save(fname)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]fname\f[I]\f[R]: A string object containing the name of the
file on which the target model is to be saved.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
On success, it writes the model information(metadata and model) in the
specified file as little-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
# saving the model
kmeans.save(\[dq]./out/MyKMeansModel\[dq])
\f[R]
.fi
.PP
The MyKMeansModel contains below directory structure:
.PD 0
.P
.PD
\f[B]MyKMeansModel\f[R]
.PD 0
.P
.PD
|\[em]\[em]metadata
.PD 0
.P
.PD
|\[em]\[em]\f[B]model\f[R]
.PP
`metadata' represents the detail about model_id, model_kind and datatype
of training vector.
.PD 0
.P
.PD
Here, the \f[B]model\f[R] directory contains information about
n_clusters_, n_features, model_kind and datatype of training vector.
.PP
This will save the Kmeans model on the path `/out/MyKMeansModel'.
It would raise exception if the directory already exists with same name.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 10. get_params(deep = True)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]deep\f[I]\f[R]: A boolean parameter, used to get parameters
and their values for an estimator.
If True, will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by Kmeans.
It is used to get parameters and their values of Kmeans class.
.PP
For example,
.IP
.nf
\f[C]
print(kmeans.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]algorithm\[aq]: \[aq]auto\[aq], \[aq]copy_x\[aq]: True, \[aq]init\[aq]: \[aq]random\[aq], \[aq]max_iter\[aq]: 300, \[aq]n_clusters\[aq]: 2, 
\[aq]n_init\[aq]: 1, \[aq]n_jobs\[aq]: 1, \[aq]precompute_distances\[aq]: \[aq]auto\[aq], \[aq]random_state\[aq]: None, 
\[aq]tol\[aq]: 0.0001, \[aq]use_shrink\[aq]: False, \[aq]verbose\[aq]: 0}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 11. set_params(**params)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]**params\f[I]\f[R]: All the keyword arguments are passed this
function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by Kmeans, used
to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print(\[dq]Get parameters before setting:\[dq]) 
print(kmeans.get_params())
# User just needs to provide the arguments and internally it will create a 
dictionary over the arguments given by user    
kmeans.set_params(n_clusters = 4, n_init = 5)
print(\[dq]Get parameters after setting:\[dq]) 
print(kmeans.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
Get parameters before setting: 
{\[aq]algorithm\[aq]: \[aq]auto\[aq], \[aq]copy_x\[aq]: True, \[aq]init\[aq]: \[aq]random\[aq], \[aq]max_iter\[aq]: 300, 
\[aq]n_clusters\[aq]: 2, \[aq]n_init\[aq]: 1, \[aq]n_jobs\[aq]: 1,\[aq]precompute_distances\[aq]: \[aq]auto\[aq], 
\[aq]random_state\[aq]: None,\[aq]tol\[aq]: 0.0001,\[aq]use_shrink\[aq]: False, \[aq]verbose\[aq]: 0}
Get parameters after setting: {\[aq]algorithm\[aq]: \[aq]auto\[aq], \[aq]copy_x\[aq]: True, 
\[aq]init\[aq]: \[aq]random\[aq], \[aq]max_iter\[aq]: 300, \[aq]n_clusters\[aq]: 4, \[aq]n_init\[aq]: 5, 
\[aq]n_jobs\[aq]: 1, \[aq]precompute_distances\[aq]: \[aq]auto\[aq], \[aq]random_state\[aq]: None, 
\[aq]tol\[aq]: 0.0001,\[aq]use_shrink\[aq]: False, \[aq]verbose\[aq]: 0}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 12. debug_print()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It shows the target model information on the server side user terminal.
It is mainly used for debugging purpose.
.PP
For example,
.IP
.nf
\f[C]
kmeans.debug_print()
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
centroid:
node = 0, local_num_row = 2, local_num_col = 3, val = 0.15 0.15 0.15 9.1 9.1 9.1
\f[R]
.fi
.PP
This output will be visible on server side.
It displays the centroid information on the trained model which is
currently present on the server.
.PP
\f[B]No such output will be visible on client side.\f[R]
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 13. release()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to release the in-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
kmeans.release()
\f[R]
.fi
.PP
This will reset the after-fit populated attributes to None, along with
releasing server side memory.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 14. is_fitted()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, predict() is used before training the model, then it can prompt
the user to train the clustering model first.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns `True', if the model is already fitted otherwise, it returns
`False'.
.SH SEE ALSO
.IP \[bu] 2
\f[B]Introduction to FrovedisRowmajorMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisCRSMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Agglomerative Clustering in Frovedis\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Spectral Clustering in Frovedis\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]DBSCAN in Frovedis\f[R]
