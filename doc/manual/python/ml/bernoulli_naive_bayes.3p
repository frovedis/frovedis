.\" Automatically generated by Pandoc 2.17.1.1
.\"
.\" Define V font for inline verbatim, using C font in formats
.\" that render this, and otherwise B font.
.ie "\f[CB]x\f[]"x" \{\
. ftr V B
. ftr VI BI
. ftr VB B
. ftr VBI BI
.\}
.el \{\
. ftr V CR
. ftr VI CI
. ftr VB CB
. ftr VBI CBI
.\}
.TH "Bernoulli Naive Bayes" "" "" "" ""
.hy
.SH NAME
.PP
BernoulliNB - One of the variations of Naive Bayes algorithm.
It is a classification algorithm to predict only binary output.
.SH SYNOPSIS
.IP
.nf
\f[C]
frovedis.mllib.naive_bayes.BernoulliNB(alpha=1.0, fit_prior=True,  
                                       class_prior=None, binarize=0.0,  
                                       verbose=0)  
\f[R]
.fi
.SS Public Member Functions
.PP
fit(X, y, sample_weight = None)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
predict_proba(X)
.PD 0
.P
.PD
score(X, y, sample_weight = None)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
Naive Bayes classifier for bernoulli models.
.PP
The Bernoulli Naive Bayes classifier is suitable for classification with
binary/boolean features.
.PP
This model is popular for document classification tasks, where binary
term occurrence features (i.e a word occurs in a document or not) are
used rather than finding the frequency of a word in document.
.PP
This module provides a client-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as Scikit-learn BernoulliNB
interface, but it doesn\[cq]t have any dependency with Scikit-learn.
It can be used simply even if the system doesn\[cq]t have Scikit-learn
installed.
Thus in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for BernoulliNB on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When prediction-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. BernoulliNB()
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]alpha\f[B]\f[R]: A positive double (float64) smoothing
parameter (0 for no smoothing).
It must be greater than or equal to 1.
(Default: 1.0)
.PD 0
.P
.PD
\f[B]\f[BI]fit_prior\f[B]\f[R]: A boolean parameter specifying whether
to learn class prior probabilities or not.
If False, a uniform prior will be used.
(Default: True)
.PD 0
.P
.PD
\f[B]\f[BI]class_prior\f[B]\f[R]: A numpy ndarray of double (float64)
type values and must be of shape \f[B](n_classes,)\f[R].
It gives prior probabilities of the classes.
(Default: None)
.PD 0
.P
.PD
When it is None (not specified explicitly), the priors are adjusted
according to the data.
.PD 0
.P
.PD
\f[B]\f[BI]binarize\f[B]\f[R]: A double (float64) parameter specifying
the threshold for binarizing sample features.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[BI]verbose\f[B]\f[R]: An integer parameter specifying the log
level to use.
Its value is 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PP
\f[B]Attributes\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]class_log_prior_\f[B]\f[R]: A python ndarray of double
(float64) type values and has shape \f[B](n_classes,)\f[R].
It contains log probability of each class (smoothed).
.PD 0
.P
.PD
\f[B]\f[BI]feature_log_prob_\f[B]\f[R]: A python ndarray of double
(float64) type values and has shape \f[B](n_classes, n_features)\f[R].
It contains empirical log probability of features given a class,
P(x_i|y).
.PD 0
.P
.PD
\f[B]\f[BI]class_count_\f[B]\f[R]: A python ndarray of double (float64)
type values and has shape \f[B](n_classes,)\f[R].
It contains the number of samples encountered for each class during
fitting.
This value is weighted by the sample weight when provided.
.PD 0
.P
.PD
\f[B]\f[BI]classes_\f[B]\f[R]: A python ndarray of double (float64) type
values and has shape \f[B](n_classes,)\f[R].
It contains the of unique labels given to the classifier during
training.
.PD 0
.P
.PD
\f[B]\f[BI]feature_count_\f[B]\f[R]: A python ndarray of double
(float64) type values and has shape \f[B](n_classes, n_features)\f[R].
It contains the number of samples encountered for each (class, feature)
during fitting.
This value is weighted by the sample weight when provided.
.PD 0
.P
.PD
\f[B]\f[BI]coef_\f[B]\f[R]: A python ndarray of double (float64) type
values.
.PD 0
.P
.PD
- If `classess_' is 2, then its shape \f[B](1, n_features)\f[R].
.PD 0
.P
.PD
- If `classess_' is more than 2, then its shape is \f[B](n_classes,
n_features)\f[R].
.PP
It mirrors `feature_log_prob_' for interpreting BernoulliNB as a linear
model.
.PD 0
.P
.PD
\f[B]\f[BI]intercept_\f[B]\f[R]: A python ndarray of double (float64)
type values.
.PD 0
.P
.PD
- If `classes_' is 2, the its shape \f[B](1,)\f[R].
.PD 0
.P
.PD
- If `classes_' is more than 2, then its shape is
\f[B](n_classes,)\f[R].
.PP
It mirrors `class_log_prior_' for interpreting BernoulliNB as a linear
model.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It initializes a BernoulliNB object with the given parameters.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 2. fit(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data.
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: Any python array-like object or an instance of
FrovedisDvector.
It has shape \f[B](n_samples,)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]sample_weight\f[B]\f[R]: A python ndarray containing the
intended weights for each input samples and it should be the shape of
\f[B](n_samples,)\f[R].
.PD 0
.P
.PD
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
(Default: None)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It accepts the training matrix (X) with labels (y) and trains a
BernoulliNB model.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample matrix and labels data  
from sklearn.datasets import load_breast_cancer  
mat, lbl = load_breast_cancer(return_X_y = True)  

# fitting input matrix and label on BernoulliNB object  
from frovedis.mllib.linear_model import BernoulliNB  
bnb = BernoulliNB(alpha = 1.0).fit(mat,lbl)  
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample matrix and labels data  
from sklearn.datasets import load_breast_cancer  
mat, lbl = load_breast_cancer(return_X_y = True)  

# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix.  
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
from frovedis.matrix.dvector import FrovedisDvector  
cmat = FrovedisRowmajorMatrix(mat)  
dlbl = FrovedisDvector(lbl)  

# BernoulliNB with pre-constructed frovedis-like inputs  
from frovedis.mllib.linear_model import BernoulliNB  
bnb = BernoulliNB(alpha = 1.0).fit(cmat, dlbl)  
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 3. predict(X)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
# predicting on BernoulliNB model
bnb.predict(mat)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[1 1 1 ... 1 1 1]
\f[R]
.fi
.PP
Like in fit(), frovedis-like input can be used to speed-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix. 
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
rmat = FrovedisRowmajorMatrix(mat)  

# predicting on BernoulliNB model using pre-constructed input  
bnb.predict(rmat)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[1 1 1 ... 1 1 1]
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a numpy array of float or double (float64) type and of shape
\f[B](n_samples,)\f[R] containing the predicted outputs.
.SS 4. predict_proba(X)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
Unlike Scikit-learn, it performs the classification on an array and
returns the probability estimates for the test feature matrix (X).
.PP
For example,
.IP
.nf
\f[C]
# finds the probability sample for each class in the model
bnb.predict_proba(mat)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
 [[0.35939685 0.64060315]
  [0.35939685 0.64060315]
  [0.35939685 0.64060315]
  ...
  [0.35939685 0.64060315]
  [0.35939685 0.64060315]
  [0.35939685 0.64060315]]
\f[R]
.fi
.PP
Like in fit(), frovedis-like input can be used to speed-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisRowmajorMatrix. 
# For scipy sparse data, FrovedisCRSMatrix should be used instead.  
from frovedis.matrix.dense import FrovedisRowmajorMatrix  
rmat = FrovedisRowmajorMatrix(mat)  

# finds the probability sample for each class in the model
bnb.predict_proba(rmat)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[[0.35939685 0.64060315]
 [0.35939685 0.64060315]
 [0.35939685 0.64060315]
 ...
 [0.35939685 0.64060315]
 [0.35939685 0.64060315]
 [0.35939685 0.64060315]]
 
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a numpy array of float or double (float64) type and of shape
\f[B](n_samples, n_classes)\f[R] containing the prediction probability
values.
.SS 5. score(X, y)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or scipy sparse matrix or any
python array-like object or an instance of FrovedisCRSMatrix for sparse
data and FrovedisRowmajorMatrix for dense data.
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: Any python array-like object containing true
labels for X.
It has shape \f[B](n_samples,)\f[R].
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
Calculate mean accuracy on the given test data and labels i.e.\ mean
accuracy of self.predict(X) wrt.
y.
.PP
For example,
.IP
.nf
\f[C]
# calculate mean accuracy score on given test data and labels
bnb.score(mat,lbl)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
0.6274
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns an accuracy score of float type.
.SS 6. debug_print()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It shows the target model information on the server side user terminal.
It is mainly used for debugging purpose.
.PP
For example,
.IP
.nf
\f[C]
bnb.debug_print()  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
model_type: bernoulli
binarize: -1
feature_count: 212 212 212 212 212  ... 357 357 357 357 357
theta: node = 0, local_num_row = 2, local_num_col = 30, val = -0.00468385 -0.00468385 
-0.00468385 -0.00468385 -0.00468385 ... -0.0027894 -0.0027894 -0.0027894 -0.0027894 -0.0027894
pi: -0.987294 -0.466145
label: 0 1
class count: 212 357
theta_minus_negtheta: node = 0, local_num_row = 2, local_num_col = 30, val = 5.36129 
5.36129 5.36129 5.36129 5.36129 ... 5.88053 5.88053 5.88053 5.88053 5.88053
negtheta_sum: -160.979 -176.5
\f[R]
.fi
.PP
This output will be visible on server side.
It displays the target model information like model_type, binarize,
feature_count, theta, pi, etc.
values on the trained model which is currently present on the server.
.PP
\f[B]No such output will be visible on client side.\f[R]
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 7. get_params(deep = True)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]deep\f[I]\f[R]: A boolean parameter, used to get parameters
and their values for an estimator.
If True, it will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by BernoulliNB.
It is used to get parameters and their values of BernoulliNB class.
.PP
For example,
.IP
.nf
\f[C]
print(bnb.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]alpha\[aq]: 1.0, \[aq]binarize\[aq]: -1.0, \[aq]class_prior\[aq]: None, \[aq]fit_prior\[aq]: True, \[aq]verbose\[aq]: 0}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 8. set_params(**params)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]**params\f[I]\f[R]: All the keyword arguments are passed to
this function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by BernoulliNB,
used to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print(\[dq]get parameters before setting:\[dq]) 
print(bnb.get_params())
# User just needs to provide the arguments and internally it will create a 
dictionary over the arguments given by user
bnb.set_params(n_clusters = 4) 
print(\[dq]get parameters after setting:\[dq]) 
print(bnb.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
get parameters before setting:
{\[aq]alpha\[aq]: 1.0, \[aq]binarize\[aq]: -1.0, \[aq]class_prior\[aq]: None, \[aq]fit_prior\[aq]: True, \[aq]verbose\[aq]: 0}
get parameters after setting:
{\[aq]alpha\[aq]: 1.0, \[aq]binarize\[aq]: 0.5, \[aq]class_prior\[aq]: None, \[aq]fit_prior\[aq]: True, \[aq]verbose\[aq]: 0}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 9. load(fname, dtype=None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]fname\f[B]\f[R]: A string object containing the name of the
file having model information such as theta, cls_count, feature_count,
label, pi, type to be loaded.
.PD 0
.P
.PD
\f[B]\f[BI]dtype\f[B]\f[R]: A data-type is inferred from the input data.
Currently, expected input data-type is either float or double (float64).
(Default: None)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It loads the model from the specified file (having little-endian binary
data).
.PP
For example,
.IP
.nf
\f[C]
bnb.load(\[dq]./out/BNBModel\[dq])
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 10. save(fname)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]fname\f[B]\f[R]: A string object containing the name of the
file on which the target model is to be saved.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
On success, it writes the model information (label_map, metadata and
model) in the specified file as little-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
# To save the bernoulli naive bayes model
bnb.save(\[dq]./out/BNBModel\[dq])    
\f[R]
.fi
.PP
This will save the naive bayes model on the path `/out/BNBModel'.
It would raise exception if the directory already exists with same name.
.PP
The `BNBModel' directory has
.PP
\f[B]BNBModel\f[R]
.PD 0
.P
.PD
|\[em]-label_map
.PD 0
.P
.PD
|\[em]-metadata
.PD 0
.P
.PD
|\[em]-\f[B]model\f[R]
.PD 0
.P
.PD
\ \ \ \ \ |\[em]\[em]cls_count
.PD 0
.P
.PD
\ \ \ \ \ |\[em]\[em]feature_count
.PD 0
.P
.PD
\ \ \ \ \ |\[em]\[em]label
.PD 0
.P
.PD
\ \ \ \ \ |\[em]\[em]pi
.PD 0
.P
.PD
\ \ \ \ \ |\[em]\[em]\f[B]theta\f[R]
.PD 0
.P
.PD
\ \ \ \ \ |\[em]\[em]type
.PP
`label_map' contains information about labels mapped with their encoded
value.
.PD 0
.P
.PD
The metadata file contains the model kind, input datatype used for
trained model.
.PD 0
.P
.PD
Here, the \f[B]model\f[R] directory contains information about class
count, feature count, labels, pi, \f[B]theta\f[R] and thier datatype.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing
.SS 11. release()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to release the in-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
bnb.release()
\f[R]
.fi
.PP
This will reset the after-fit populated attributes to None, along with
releasing server side memory.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 12. is_fitted()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, predict() is used before training the model, then it can prompt
the user to train the naive bayes model first.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns `True', if the model is already fitted, otherwise, it returns
`False'.
.SH SEE ALSO
.IP \[bu] 2
\f[B]Introduction to FrovedisRowmajorMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisCRSMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisDvector\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Multinomial Naive Bayes in Frovedis\f[R]
