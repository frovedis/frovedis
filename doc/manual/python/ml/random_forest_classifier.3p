.\" Automatically generated by Pandoc 2.17.1.1
.\"
.\" Define V font for inline verbatim, using C font in formats
.\" that render this, and otherwise B font.
.ie "\f[CB]x\f[]"x" \{\
. ftr V B
. ftr VI BI
. ftr VB B
. ftr VBI BI
.\}
.el \{\
. ftr V CR
. ftr VI CI
. ftr VB CB
. ftr VBI CBI
.\}
.TH "RandomForestClassifier" "" "" "" ""
.hy
.SH NAME
.PP
RandomForestClassifier - A classification algorithm that contains
multiple decision trees on various subsets of the given dataset.
It contains the predictions of multiple decision trees and based on the
majority votes of predictions, it predicts the final output.
.SH SYNOPSIS
.IP
.nf
\f[C]
class frovedis.mllib.ensemble.forest.RandomForestClassifier(n_estimators=100, criterion=\[aq]gini\[aq],  
                                                            max_depth=None,  
                                                            min_samples_split=2,  
                                                            min_samples_leaf=1,  
                                                            min_weight_fraction_leaf=0.0,  
                                                            max_features=\[aq]auto\[aq],  
                                                            max_leaf_nodes=None,  
                                                            min_impurity_decrease=0.0,  
                                                            min_impurity_split=None,  
                                                            bootstrap=True, oob_score=False,  
                                                            n_jobs=None, random_state=None,  
                                                            verbose=0, warm_start=False,  
                                                            class_weight=None, ccp_alpha=0.0,  
                                                            max_samples=None, max_bins=32)  
\f[R]
.fi
.SS Public Member Functions
.PP
fit(X, y)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
score(X, y, sample_weight = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
Random Forest Classifier is a supervised machine learning algorithm used
for classification using decision trees.
The classifier creates a set of decision trees from randomly selected
subsets of the training set.
It is basically a set of decision trees from a randomly selected subset
of the training set and then it collects the votes from different
decision trees to decide the final prediction.
\f[B]Frovedis supports both binary and multinomial random forest
classification algorithms.\f[R]
.PP
During training, the input \f[B]X\f[R] is the training data and
\f[B]y\f[R] is the corresponding label values (Frovedis supports any
values for labels, but internally it encodes the input binary labels to
0 and 1, and input multinomial labels to 0, 1, 2, \&..., N-1 (where N is
the no.
of classes) before training at Frovedis server) which we want to
predict.
.PP
This module provides a client-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as Scikit-learn
RandomForestClassifier interface, but it doesn\[cq]t have any dependency
with Scikit-learn.
It can be used simply even if the system doesn\[cq]t have Scikit-learn
installed.
Thus in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for RandomForestClassifier on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When prediction-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. RandomForestClassifier()
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]n_estimators\f[B]\f[R]: A positive integer parameter that
specifies the number of trees in the forest.
(Default: 100)
.PD 0
.P
.PD
\f[B]\f[BI]criterion\f[B]\f[R]: A string object parameter that specifies
the function to measure the quality of a split.
Supported criteria are `gini' and `entropy'.
(Default: `gini')
.PD 0
.P
.PD
- \f[B]`gini' impurity\f[R]: calculates the amount of probability of a
specific feature that is classified incorrectly when selected randomly.
.PD 0
.P
.PD
- \f[B]`entropy' (information gain)\f[R]: it is applied to quantify
which feature provides maximal information about the classification
based on the notion of entropy.
.PP
\f[B]\f[BI]max_depth\f[B]\f[R]: A positive integer parameter that
specifies the maximum depth of the tree.
(Default: None)
.PD 0
.P
.PD
If it is None (not specified explicitly), then `max_depth' is set to 4.
.PD 0
.P
.PD
\f[B]\f[BI]min_samples_split\f[B]\f[R]: An integer or float value that
specifies the minimum number of samples required to split an internal
node.
(Default: 2)
.PD 0
.P
.PD
\f[B]\f[BI]min_samples_leaf\f[B]\f[R]: A positive integer or float value
that specifies the minimum number of samples required to be at a leaf
node.
A split point at any depth will only be considered if it leaves at least
`min_samples_leaf' training samples in each of the left and right
branches.
(Default: 1)
.PD 0
.P
.PD
- If it is an integer, then `min_samples_leaf' should be greater than 0.
.PD 0
.P
.PD
- If it is float, then it is set as
\f[B]int(np.ceil(self.min_samples_split * self.n_samples_))\f[R]
.PP
\f[B]\f[BI]min_weight_fraction_leaf\f[B]\f[R]: An unused parameter.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[BI]max_features\f[B]\f[R]: A string object parameter that
specifies the number of features to consider when looking for the best
split:
.PD 0
.P
.PD
- If it is an integer, then it will be set as \f[B](max_features * 1.0)
/ n_features_\f[R].
.PD 0
.P
.PD
- If it is float, then it will be \f[B]`max_features'\f[R] number of
features at each split.
.PD 0
.P
.PD
- If it is `auto', then it will be set as \f[B]sqrt(n_features_)\f[R].
.PD 0
.P
.PD
- If `sqrt', then it will be set as \f[B]sqrt(n_features_)\f[R] (same as
`auto').
.PD 0
.P
.PD
- If `log2', then it will be set as \f[B]log2(n_features_)\f[R].
.PD 0
.P
.PD
- If None, then it will be set as \f[B]n_features_\f[R].
(Default: `auto')
.PP
\f[B]\f[BI]max_leaf_nodes\f[B]\f[R]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[BI]min_impurity_decrease\f[B]\f[R]: A positive double (float64)
parameter.
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[BI]min_impurity_split\f[B]\f[R]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]bootstrap\f[R]: An unused parameter.
(Default: True)
.PD 0
.P
.PD
\f[B]oob_score\f[R]: An unused parameter.
(Default: False)
.PD 0
.P
.PD
\f[B]n_jobs\f[R]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[BI]random_state\f[B]\f[R]: An integer parameter that controls
the sampling of the features to consider when looking for the best split
at each node (if max_features < n_features).
(Default: None)
.PD 0
.P
.PD
If it is None (not specified explicitly), then `random_state' is set as
-1.
.PD 0
.P
.PD
\f[B]\f[BI]verbose\f[B]\f[R]: An integer parameter specifying the log
level to use.
Its value is set as 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PD 0
.P
.PD
\f[B]\f[BI]warm_start\f[B]\f[R]: An unused parameter.
(Default: False)
.PD 0
.P
.PD
\f[B]\f[BI]class_weight\f[B]\f[R]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[BI]ccp_alpha\f[B]\f[R]: An unused parameter.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[BI]max_samples\f[B]\f[R]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[BI]max_bins\f[B]\f[R]: A positive integer parameter that
specifies the maximum number of bins created by ordered splits.
(Default: 32)
.PP
\f[B]Attributes\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]classes_\f[B]\f[R]: It is a python ndarray (any type) of
unique labels given to the classifier during training.
It has shape \f[B](n_classes,)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]n_features_\f[B]\f[R]: An integer value specifying the number
of features when fitting the estimator.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It initializes a RandomForestClassifier object with the given
parameters.
.PP
The parameters: \[lq]min_weight_fraction_leaf\[rq],
\[lq]max_leaf_nodes\[rq], \[lq]min_impurity_split\[rq],
\[lq]bootstrap\[rq], \[lq]oob_score\[rq], \[lq]n_jobs\[rq],
\[lq]warm_start\[rq], \[lq]class_weight\[rq], \[lq]ccp_alpha\[rq] and
\[lq]max_samples\[rq] are simply kept in to make the interface uniform
to the Scikit-learn RandomForestClassifier module.
They are not used anywhere within frovedis implementation.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 2. fit(X, y)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or any python array-like object or
an instance of FrovedisColmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[R].
Currently, it supports only dense data as input.
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: Any python array-like object or an instance of
FrovedisDvector containing the target values.
It has shape \f[B](n_samples,)\f[R].
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It builds a forest of trees from the training data X and labels y.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample matrix and labels dense data
import numpy as np
mat = np.array([[10, 0, 1, 0, 0, 1, 0],
                [0, 1, 0, 1, 0, 1, 0],
                [0, 1, 0, 0, 1, 0, 1],
                [1, 0, 0, 1, 0, 1, 0]], dtype = np.float64)
lbl = np.array([100, 500, 100, 600], dtype = np.float64) 

# fitting input matrix and label on RandomForestClassifier object
from frovedis.mllib.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 10, max_depth = 4, min_samples_split = 0.5
                             min_samples_leaf = 1.2, random_state = 324)  
rfc.fit(mat,lbl)
\f[R]
.fi
.PP
When native python data is provided, it is converted to frovedis-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre-constructed frovedis-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
# loading a sample matrix and labels dense data
import numpy as np
mat = np.array([[10, 0, 1, 0, 0, 1, 0],
                [0, 1, 0, 1, 0, 1, 0],
                [0, 1, 0, 0, 1, 0, 1],
                [1, 0, 0, 1, 0, 1, 0]], dtype = np.float64)
lbl = np.array([100, 500, 100, 600], dtype = np.float64) 

# Since \[dq]mat\[dq] is numpy dense data, we have created FrovedisColmajorMatrix. 
# For scipy sparse data, FrovedisCRSMatrix should be used instead.
from frovedis.matrix.dense import FrovedisColmajorMatrix
from frovedis.matrix.dvector import FrovedisDvector 
cmat = FrovedisColmajorMatrix(mat)
dlbl = FrovedisDvector(lbl)

# fitting input matrix and label on RandomForestClassifier object
from frovedis.mllib.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 10, max_depth = 4,
                             min_samples_split = 0.5, min_samples_leaf = 1.2, 
                             random_state = 324)  
rfc.fit(cmat,dlbl)
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 3. predict(X)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or any python array-like object or
an instance of FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[R].
Currently, it supports only dense data as input.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
Predict class for X.
.PP
The predicted class of an input sample is a vote by the trees in the
forest, weighted by their probability estimates.
That is, the predicted class is the one with highest mean probability
estimate across the trees.
.PP
For example,
.IP
.nf
\f[C]
# predicting on random forest classifier model
rfc.predict(mat)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[100. 500. 100. 500.]
\f[R]
.fi
.PP
Like in fit(), frovedis-like input can be used to speed-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
# Since \[dq]cmat\[dq] is FrovedisColmajorMatrix, we have created FrovedisRowmajorMatrix.
# predicting on random forest classifier model
rfc.predict(cmat.to_frovedis_rowmatrix())  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
[100. 500. 100. 500.]
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns a numpy array of float or double (float64) type and of shape
\f[B](n_samples,)\f[R] containing the predicted classes.
.SS 4. get_params(deep = True)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]deep\f[I]\f[R]: A boolean parameter, used to get parameters
and their values for an estimator.
If True, it will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
RandomForestClassifier.
It is used to get parameters and their values of RandomForestClassifier
class.
.PP
For example,
.IP
.nf
\f[C]
print(rfc.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]bootstrap\[aq]: True, \[aq]ccp_alpha\[aq]: 0.0, \[aq]class_weight\[aq]: None, \[aq]criterion\[aq]: \[aq]gini\[aq], 
\[aq]max_bins\[aq]: 32, \[aq]max_depth\[aq]: 4, \[aq]max_features\[aq]: \[aq]auto\[aq], \[aq]max_leaf_nodes\[aq]: None, 
\[aq]max_samples\[aq]: None, \[aq]min_impurity_decrease\[aq]: 0.0, \[aq]min_impurity_split\[aq]: None, 
\[aq]min_samples_leaf\[aq]: 2, \[aq]min_samples_split\[aq]: 0.5, \[aq]min_weight_fraction_leaf\[aq]: 0.0, 
\[aq]n_estimators\[aq]: 10, \[aq]n_jobs\[aq]: None, \[aq]oob_score\[aq]: False, \[aq]random_state\[aq]: 324, 
\[aq]verbose\[aq]: 0, \[aq]warm_start\[aq]: False}
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 5. set_params(**params)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[I]\f[BI]**params\f[I]\f[R]: All the keyword arguments are passed to
this function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
RandomForestClassifier, used to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print(\[dq]get parameters before setting:\[dq]) 
print(rfc.get_params())
# User just needs to provide the arguments and internally it will create a 
dictionary over the arguments given by user
rfc.set_params(criterion = \[aq]entropy\[aq], max_depth = 5) 
print(\[dq]get parameters after setting:\[dq]) 
print(rfc.get_params())
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
get parameters before setting:  
{\[aq]bootstrap\[aq]: True, \[aq]ccp_alpha\[aq]: 0.0, \[aq]class_weight\[aq]: None, \[aq]criterion\[aq]: \[aq]gini\[aq], 
\[aq]max_bins\[aq]: 32, \[aq]max_depth\[aq]: 4, \[aq]max_features\[aq]: \[aq]auto\[aq], \[aq]max_leaf_nodes\[aq]: None, 
\[aq]max_samples\[aq]: None, \[aq]min_impurity_decrease\[aq]: 0.0, \[aq]min_impurity_split\[aq]: None, 
\[aq]min_samples_leaf\[aq]: 2, \[aq]min_samples_split\[aq]: 0.5, \[aq]min_weight_fraction_leaf\[aq]: 0.0, 
\[aq]n_estimators\[aq]: 10, \[aq]n_jobs\[aq]: None, \[aq]oob_score\[aq]: False, \[aq]random_state\[aq]: 324, 
\[aq]verbose\[aq]: 0, \[aq]warm_start\[aq]: False}  
get parameters after setting:    
{\[aq]bootstrap\[aq]: True, \[aq]ccp_alpha\[aq]: 0.0, \[aq]class_weight\[aq]: None, \[aq]criterion\[aq]: \[aq]entropy\[aq], 
\[aq]max_bins\[aq]: 32, \[aq]max_depth\[aq]: 5, \[aq]max_features\[aq]: \[aq]auto\[aq], \[aq]max_leaf_nodes\[aq]: None, 
\[aq]max_samples\[aq]: None, \[aq]min_impurity_decrease\[aq]: 0.0, \[aq]min_impurity_split\[aq]: None, 
\[aq]min_samples_leaf\[aq]: 2, \[aq]min_samples_split\[aq]: 0.5, \[aq]min_weight_fraction_leaf\[aq]: 0.0, 
\[aq]n_estimators\[aq]: 10, \[aq]n_jobs\[aq]: None, \[aq]oob_score\[aq]: False, \[aq]random_state\[aq]: 324, 
\[aq]verbose\[aq]: 0, \[aq]warm_start\[aq]: False}  
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 6. load(fname, dtype = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]fname\f[B]\f[R]: A string object containing the name of the
file having model information to be loaded.
.PD 0
.P
.PD
\f[B]\f[BI]dtype\f[B]\f[R]: A data-type is inferred from the input data.
Currently, expected input data-type is either float or double (float64).
(Default: None)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It loads the model from the specified file (having little-endian binary
data).
.PP
For example,
.IP
.nf
\f[C]
rfc.load(\[dq]./out/rf_classifier_model\[dq])  
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It simply returns \[lq]self\[rq] reference.
.SS 7. save(fname)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]fname\f[B]\f[R]: A string object containing the name of the
file on which the target model is to be saved.
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
On success, it writes the model information (label_map, metadata and
model) in the specified file as little-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
# To save the random forest classifier model
dtc.save(\[dq]./out/rf_classifier_model\[dq])  
\f[R]
.fi
.PP
This will save the random forest classifier model on the path
\[lq]/out/rf_classifier_model\[rq].
It would raise exception if the directory already exists with same name.
.PP
The `rf_classifier_model' directory has
.PP
\f[B]rf_classifier_model\f[R]
.PD 0
.P
.PD
|\[em]\[en]label_map
.PD 0
.P
.PD
|\[em]\[en]metadata
.PD 0
.P
.PD
|\[em]\[en]model
.PP
`label_map' file contains information about labels mapped with their
encoded value.
.PD 0
.P
.PD
The `metadata' file contains the number of classes, model kind and input
datatype used for trained model.
.PD 0
.P
.PD
The `model' file contains the random forest model saved in binary
format.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 8. score(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[R]
.PD 0
.P
.PD
\f[B]\f[BI]X\f[B]\f[R]: A numpy dense or any python array-like object or
an instance of FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[R].
Currently, it supports only dense data as input.
.PD 0
.P
.PD
\f[B]\f[BI]y\f[B]\f[R]: Any python array-like object containing the true
labels for X.
It has shape \f[B](n_samples,)\f[R].
.PD 0
.P
.PD
\f[B]\f[BI]sample_weight\f[B]\f[R]: A python ndarray containing the
intended weights for each input samples and it should be the shape of
\f[B](n_samples,)\f[R].
.PD 0
.P
.PD
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
(Default: None)
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
Calculate mean accuracy on the given test data and labels i.e.\ mean
accuracy of self.predict(X) wrt.
y.
.PP
For example,
.IP
.nf
\f[C]
# calculate mean accuracy score on given test data and labels
rfc.score(mat,lbl)  
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
0.75
\f[R]
.fi
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns an accuracy score of float type.
.SS 9. debug_print()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It shows the target model information on the server side user terminal.
It is mainly used for debugging purpose.
.PP
For example,
.IP
.nf
\f[C]
rfc.debug_print()
\f[R]
.fi
.PP
Output
.IP
.nf
\f[C]
-------- Classification Trees (Random Forest):: --------
# of trees: 10
---- [0] ----
  # of nodes: 3, height: 1
  <1> Split: feature[2] < 0.25, IG: 0.5
   \[rs]_ (2) Predict: 2 (100%)
   \[rs]_ (3) Predict: 0 (100%)
---- [1] ----
  # of nodes: 3, height: 1
  <1> Split: feature[6] < 0.25, IG: 0.375
   \[rs]_ (2) Predict: 1 (50%)
   \[rs]_ (3) Predict: 0 (100%)
---- [2] ----
  # of nodes: 1, height: 0
  (1) Predict: 0 (50%)
---- [3] ----
  # of nodes: 3, height: 1
  <1> Split: feature[6] < 0.25, IG: 0.125
   \[rs]_ (2) Predict: 0 (50%)
   \[rs]_ (3) Predict: 0 (100%)
---- [4] ----
  # of nodes: 3, height: 1
  <1> Split: feature[3] < 0.25, IG: 0.375
   \[rs]_ (2) Predict: 0 (100%)
   \[rs]_ (3) Predict: 1 (50%)
---- [5] ----
  # of nodes: 3, height: 1
  <1> Split: feature[1] < 0.25, IG: 0.5
   \[rs]_ (2) Predict: 2 (100%)
   \[rs]_ (3) Predict: 1 (100%)
---- [6] ----
  # of nodes: 1, height: 0
  (1) Predict: 0 (100%)
---- [7] ----
  # of nodes: 1, height: 0
  (1) Predict: 2 (75%)
---- [8] ----
  # of nodes: 1, height: 0
  (1) Predict: 1 (50%)
---- [9] ----
  # of nodes: 3, height: 1
  <1> Split: feature[5] < 0.25, IG: 0.375
   \[rs]_ (2) Predict: 0 (100%)
   \[rs]_ (3) Predict: 1 (50%)
\f[R]
.fi
.PP
This output will be visible on server side.
It displays the random forest having maximum depth of 4 and total 10
decision trees.
.PP
\f[B]No such output will be visible on client side.\f[R]
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 10. release()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to release the in-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
rfc.release()
\f[R]
.fi
.PP
This will reset the after-fit populated attributes (like classes_,
n_features_) to None, along with releasing server side memory.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns nothing.
.SS 11. is_fitted()
.PP
\f[B]Purpose\f[R]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
.PP
\f[B]Return Value\f[R]
.PD 0
.P
.PD
It returns `True', if the model is already fitted, otherwise, it returns
`False'.
.SH SEE ALSO
.IP \[bu] 2
\f[B]Introduction to FrovedisRowmajorMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisColmajorMatrix\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Introduction to FrovedisDvector\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Random Forest Regressor in Frovedis\f[R]
.PD 0
.P
.PD
.IP \[bu] 2
\f[B]Decision Tree Classifier in Frovedis\f[R]
