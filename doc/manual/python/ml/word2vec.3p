.TH "Word2Vec" "" "" "" ""
.SH NAME
.PP
Word2Vec \- Word embedding is one of the most popular representation of
document vocabulary.
It is capable of capturing context of a word in a document, semantic and
syntactic similarity, relation with other words, etc.
.SH SYNOPSIS
.PP
class frovedis.mllib.feature.Word2Vec(sentences=None, corpusFile=None,
outDirPath=None,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ hiddenSize=100,
learningRate=0.025, n_iter=1,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ minCount=5, window=5,
threshold=1e\-3,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ negative=5, modelSyncPeriod=0.1,
minSyncWords=1024,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ fullSyncTimes=0, messageSize=1024,
numThreads=None)
.SS Public Member Functions
.PP
build_vocab(corpusIterable = None, corpusFile = None, outDirPath = None,
update = False)
.PD 0
.P
.PD
build_vocab_and_dump(corpusIterable = None, corpusFile = None,
outDirPath = None, update = False)
.PD 0
.P
.PD
to_gensim_model()
.PD 0
.P
.PD
train(corpusIterable = None, corpusFile = None)
.PD 0
.P
.PD
fit(corpusIterable = None, corpusFile = None)
.PD 0
.P
.PD
save(modelPath, binary = False)
.PD 0
.P
.PD
transform(corpusIterable = None, corpusFile = None, func = None)
.PD 0
.P
.PD
fit_transform(corpusIterable = None, corpusFile = None, func = None)
.SH DESCRIPTION
.PP
Word2vec is a two\-layer neural net that processes text by “vectorizing”
words.
Its input is a text corpus and its output is a set of vectors (feature
vectors that represent words in that corpus).
While Word2vec is not a deep neural network, it turns text into a
numerical form that deep neural networks can understand.
.PP
Word2vec's applications extend beyond parsing sentences in the wild.
It can be applied just as well to genes, code, likes, playlists, social
media graphs and other verbal or symbolic series in which patterns may
be discerned.
.PP
This module provides a client\-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as Gensim Word2Vec interface.
It needs to be used when a system has Gensim installed.
Thus in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for Word2Vec on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When transform\-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. Word2Vec()
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]sentences\f[]\f[]: This parameter is an iterable of list of
strings.
If not provided, the \[aq]corpusFile\[aq] parameter must be provided for
creating the model.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter which specifies
the path to a corpus file.
If not provided, the \[aq]sentences\[aq] parameter must be provided for
creating the model.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]outDirPath\f[]\f[]: A string object parameter specifying the
path of output directory.
The newly built vocabulary generated from the input data file is dumped
into the provided output file path.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]hiddenSize\f[]\f[]: An integer parameter specifying the
dimensionality of the word vectors.
For fast computation, this value should be an even value and less than
512 during training.
(Default: 100)
.PD 0
.P
.PD
\f[B]\f[I]learningRate\f[]\f[]: An unused parameter specifying the
initial learning rate.
(Default: 0.025)
.PD 0
.P
.PD
\f[B]\f[I]n_iter\f[]\f[]: An unused parameter specifying the number of
iterations over the corpus.
(Default: 1)
.PD 0
.P
.PD
\f[B]\f[I]minCount\f[]\f[]: An integer parameter that ignores all words
with total frequency lower than this value during vocabulary building.
This value should be within 1 to largest total frequency of a word in
vocabulary.
(Default: 5)
.PD 0
.P
.PD
\f[B]\f[I]window\f[]\f[]: An integer parameter specifying the maximum
distance between the current and predicted word within a sentence.
For fast computation, this value should be less than or equal to 8
during training.
(Default: 5)
.PD 0
.P
.PD
\f[B]\f[I]threshold\f[]\f[]: An unused parameter specifying the
threshold for configuring which higher\-frequency words are randomly
downsampled.
(Default: 1e\-3)
.PD 0
.P
.PD
\f[B]\f[I]negative\f[]\f[]: An integer parameter.
This value specifies how many "noise words" should be drawn (usually
between 5\-20).
The default value should be used for fast computation during training.
(Default: 5)
.PD 0
.P
.PD
\f[B]\f[I]modelSyncPeriod\f[]\f[]: An unused parameter specifying the
model synchronous period.
(Default: 0.1)
.PD 0
.P
.PD
\f[B]\f[I]minSyncWords\f[]\f[]: An unused parameter specifying the
minimum number of words to be synced at each model sync.
(Default: 1024)
.PD 0
.P
.PD
\f[B]\f[I]fullSyncTimes\f[]\f[]: An unused parameter specifying the
full\-model sync\-up time during training.
(Default: 0)
.PD 0
.P
.PD
\f[B]\f[I]messageSize\f[]\f[]: An unused parameter specifying the
message size in megabytes.
(Default: 1024)
.PD 0
.P
.PD
\f[B]\f[I]numThreads\f[]\f[]: An integer parameter specifying the number
of worker threads to be used to train the model.
Ideally, the number of threads should range between 1 and 8.
(Default: None)
.PD 0
.P
.PD
In case the environment variable \[aq]VE_OMP_NUM_THREADS\[aq] is
defined, then the value for \[aq]numThreads\[aq] would be derived from
VE_OMP_NUM_THREADS, otherwise, \[aq]numThreads\[aq] would default to
value 1.
.PD 0
.P
.PD
\f[B]Attributes\f[]
.PD 0
.P
.PD
\f[B]\f[I]wv\f[]\f[]: The trained words are stored in KeyedVectors
(mapping between keys such as words and embeddings as arrays) instance.
It contains the mapping between words and embeddings.
.PP
For example,
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ \ \ \ 

#\ Training\ the\ Word2Vec\ model\ using\ build_vocab()\ and\ train()
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab(data)\ 
wv_model.train(data)\ 
print(wv_model.wv)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]</s>\[aq]:\ array([\ 0.00400269,\ \ 0.0044194\ ,\ \-0.00383026,\ ...,\ \ 0.0015239\ ,\ \ 0.00305939,
\ \ \ \ 0.00019363]),\ \[aq]say\[aq]:\ array([\ 0.00227966,\ \-0.00495255,\ \ 0.00431488,\ ...,\ \ 0.00019882,
\ \ \ \ \-0.0016861\ ,\ \-0.00112656])}
\f[]
.fi
.PP
It displays words as keys and embeddings as arrays.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It initializes a Word2Vec object with the given parameters.
.PP
The parameters: "learningRate", "n_iter", "threshold",
"modelSyncPeriod", "minSyncWords", "fullSyncTimes" and "messageSize" are
simply kept in to to make the interface uniform to the gensim Word2Vec
module.
They are not used anywhere within the frovedis implementation.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 2. build_vocab(corpusIterable = None, corpusFile = None, outDirPath
= None, update = False)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]corpusIterable\f[]\f[]: Use the \[aq]sentences\[aq] iterable
which itself must be an iterable of list of list of tokens.
If None, the \[aq]corpusFile\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter specifying the
path of a corpus file.
If None, the \[aq]corpusIterable\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]outDirPath\f[]\f[]: A string object parameter specifying the
path of output directory \[aq]./out\[aq].
The newly built vocabulary generated from the input data file is dumped
into provided output file path.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]update\f[]\f[]: A boolean parameter if set to True, will add
the new words present in sentences to the model's vocabulary.
(Default: False)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It builds the vocabulary from input data file and dumped into provided
output files.
It also initializes the \[aq]wv\[aq] attribute.
.PP
For example, building vocabulary from an iterable
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ 

#\ Building\ vocabulary\ from\ input\ iterable\ data\ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2vec(minCount\ =\ 2)
wv_model.build_vocab(corpusIterable\ =\ data)\ \ \ 
\f[]
.fi
.PP
For example, building vocabulary from a text file
.IP
.nf
\f[C]
#\ Using\ a\ text\ file\ \ 
textfile\ =\ "./input/text8\-10k"
modelpath\ =\ "./out/text_model.txt"

#\ Building\ vocabulary\ from\ input\ text\ file\ \ \ \ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab(corpusFile\ =\ textfile,\ outDirPath\ =\ modelpath)\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 3. build_vocab_and_dump(corpusIterable = None, corpusFile = None,
outDirPath = None, update = False)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]corpusIterable\f[]\f[]: Use the \[aq]sentences\[aq] iterable
which itself must be an iterable of list of list of tokens.
If None, the \[aq]corpusFile\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter specifying the
path to a corpus file.
If None, the \[aq]corpusIterable\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]outDirPath\f[]\f[]: A string object parameter specifying the
path to output directory \[aq]./out\[aq].
The newly build vocabulary generated from the input data file is dumped
into provided output file path.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]update\f[]\f[]: A boolean parameter if set to True, will add
the new words present in sentences to the model's vocabulary.
(Default: False)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It builds the vocabulary from input data file and dump into provided
output files.
It also initializes the \[aq]wv\[aq] attribute.
This method is an alias to build_vocab().
.PP
For example, building vocabulary from an iterable
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ \ \ \ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ \ 

#\ Building\ vocabulary\ from\ input\ iterable\ data\ \ \ \ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2vec(minCount\ =\ 2)
wv_model.build_vocab_and_dump(corpusIterable\ =\ data)\ \ \ 
\f[]
.fi
.PP
For example, building vocabulary from a text file
.IP
.nf
\f[C]
#\ Using\ a\ text\ file\ \ \ \ 
textfile\ =\ "./input/text8\-10k"
modelpath\ =\ "./out/text_model.txt"

#\ Building\ vocabulary\ from\ input\ text\ file\ \ \ \ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab_and_dump(corpusFile\ =\ textfile,\ outDirPath\ =\ modelpath)\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 4. to_gensim_model()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It generates a gensim like \[aq]wv\[aq] (KeyedVectors instance)
attribute for Word2Vec model.
.PP
For example,
.IP
.nf
\f[C]
wv_model.to_gensim_model()
\f[]
.fi
.PP
\f[B]Note:\-\f[] In order to use this method, gensim version installed
by users needs to be 4.0.1 or above.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns gensim like KeyedVectors instance.
.SS 5. train(corpusIterable = None, corpusFile = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]corpusIterable\f[]\f[]: Use the \[aq]sentences\[aq] iterable
which itself must be an iterable of list of list of tokens.
If None, the \[aq]corpusFile\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter specifying the
path to a corpus file.
If None, the \[aq]corpusIterable\[aq] must be provided for building the
vocabulary.
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It trains the Word2Vec model on input vocabulary.
.PP
For example, training with an iterable data
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ 

#\ Training\ the\ model\ \ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2vec(minCount\ =\ 2)
wv_model.build_vocab(corpusIterable\ =\ data)
wv_model.train(corpusIterable\ =\ data)\ \ 
\f[]
.fi
.PP
For example, training with a text file
.IP
.nf
\f[C]
#\ Using\ a\ text\ file\ \ 
textfile\ =\ "./input/text8\-10k"
modelpath\ =\ "./out/text_model.txt"

#\ Training\ the\ model\ \ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab(corpusFile\ =\ textfile,\ outDirPath\ =\ modelpath)\ \ 
wv_model.train(corpusFile\ =\ textfile)\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 6. fit(corpusIterable = None, corpusFile = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]corpusIterable\f[]\f[]: Use the \[aq]sentences\[aq] iterable
which itself must be an iterable of list of list of tokens.
If None, the \[aq]corpusFile\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter specifying the
path to a corpus file.
If None, the \[aq]corpusIterable\[aq] must be provided for building the
vocabulary.
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It trains the Word2Vec model on input vocabulary.
This method is an alias to train().
.PP
For example, training with an iterable data
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ 

#\ Training\ the\ model
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2vec(minCount\ =\ 2)
wv_model.build_vocab(corpusIterable\ =\ data)
wv_model.fit(corpusIterable\ =\ data)\ \ 
\f[]
.fi
.PP
For example, training with a text file
.IP
.nf
\f[C]
#\ Using\ a\ text\ file\ \ 
textfile\ =\ "./input/text8\-10k"
modelpath\ =\ "./out/text_model.txt"

#\ Training\ the\ model\ \ \ \ \ \ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab(corpusFile\ =\ textfile,\ outDirPath\ =\ modelpath)\ \ 
wv_model.fit(corpusFile\ =\ textfile)\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 7. save(modelPath, binary = False)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]modelPath\f[]\f[]: A string object parameter specifying the
path of the output file in order to save the embeddings.
.PD 0
.P
.PD
\f[B]\f[I]binary\f[]\f[]: A boolean parameter if set to True, will save
the data in binary format, otherwise, it will be saved in plain text.
(Default: False)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It saves the word2vec model information to a file.
.PP
On success, it writes the model information (after\-fit populated
attribute like \[aq]wv\[aq]) in the specified file as little\-endian
binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
#\ To\ save\ the\ word\ embeddings\ in\ a\ file
model\ =\ "./out/text_model.txt"\ \ 
wv_model.save(model,\ binary\ =\ False)\ \ 
\f[]
.fi
.PP
This will save the word2vec model information on the path
"/out/text_model.txt".
.PD 0
.P
.PD
It would raise exception if the \[aq]text_model.txt\[aq] file already
existed with same name.
.PP
The \[aq]text_model.txt\[aq] file contains the count of all the words
with total frequency greater than \[aq]minCount\[aq],
\[aq]hiddenSize\[aq] and dictionary having words (as keys) and
embeddings (as values).
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 8. transform(corpusIterable = None, corpusFile = None, func = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]corpusIterable\f[]\f[]: Use the \[aq]sentences\[aq] iterable
which itself must be an iterable of list of list of tokens.
If None, the \[aq]corpusFile\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter specifying the
path to a corpus file.
If None, the \[aq]corpusIterable\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]func\f[]\f[]: A function to apply on document vector.
(Default: None) If None, then np.mean() is used as \[aq]func\[aq].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It transforms the document text to word2vec embeddings.
.PP
For example, training with an iterable
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ 

#\ Training\ the\ model\ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2vec(minCount\ =\ 2)
wv_model.build_vocab(corpusIterable\ =\ data)
wv_model.fit(corpusIterable\ =\ data)
embeddings\ =\ wv_model.transform(corpusIterable\ =\ data)
print(embeddings)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[[\ 0.00227966\ \-0.00495255\ \ 0.00431488\ ...\ \ 0.00019882\ \-0.0016861
\ \ \-0.00112656]
\ [\ 0.00227966\ \-0.00495255\ \ 0.00431488\ ...\ \ 0.00019882\ \-0.0016861
\ \ \-0.00112656]]
\f[]
.fi
.PP
For example, training with a text file
.IP
.nf
\f[C]
#\ Using\ a\ text\ file\ \ 
textfile\ =\ "./input/text8\-10k"

#\ Training\ the\ model\ 
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab(corpusFile\ =\ textfile)
wv_model.fit(corpusFile\ =\ textfile)
embeddings\ =\ wv_model.transform(corpusFile\ =\ textfile)
print(embeddings)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[[\-0.00013626\ \-0.00059639\ \ 0.00063703\ ...\ \ 0.0004084\ \ \-0.00033636
\ \ \-0.00013291]]\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns document embeddings (numpy array) of shape \f[B](n_samples,
hiddenSize)\f[].
.SS 9. fit_transform(corpusIterable = None, corpusFile = None, func =
None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]corpusIterable\f[]\f[]: Use the \[aq]sentences\[aq] iterable
which itself must be an iterable of list of list of tokens.
If None, the \[aq]corpusFile\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]corpusFile\f[]\f[]: A string object parameter specifying the
path to a corpus file.
If None, the \[aq]corpusIterable\[aq] must be provided for building the
vocabulary.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]func\f[]\f[]: A function to apply on document vector.
(Default: None) If None, then np.mean() is used as \[aq]func\[aq].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It trains the word2vec model on input document and transforms the
document text to word2vec embeddings.
.PP
For example, training with an iterable
.IP
.nf
\f[C]
#\ Using\ an\ iterable\ data\ \ 
data\ =\ [["cat",\ "say",\ "meow"],\ ["dog",\ "say",\ "woof"]]\ 

#\ Training\ the\ model\ 
from\ frovedis.mllib\ import\ Word2Vec
wv_model\ =\ Word2vec(minCount\ =\ 2)
wv_model.build_vocab(corpusIterable\ =\ data)
embeddings\ =\ wv_model.fit_transform(corpusIterable\ =\ data)
print(embeddings)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[[\ 0.00227966\ \-0.00495255\ \ 0.00431488\ ...\ \ 0.00019882\ \-0.0016861
\ \ \-0.00112656]
\ [\ 0.00227966\ \-0.00495255\ \ 0.00431488\ ...\ \ 0.00019882\ \-0.0016861
\ \ \-0.00112656]]
\f[]
.fi
.PP
For example, with a text file
.IP
.nf
\f[C]
#\ Using\ a\ text\ file\ \ 
textfile\ =\ "./input/text8\-10k"

#\ Training\ the\ model\ 
wv_model\ =\ Word2Vec(minCount\ =\ 2)
wv_model.build_vocab(corpusFile\ =\ textfile)
embeddings\ =\ wv_model.fit_transform(corpusFile\ =\ textfile)
print(embeddings)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[[\-0.00013626\ \-0.00059639\ \ 0.00063703\ ...\ \ 0.0004084\ \ \-0.00033636
\ \ \-0.00013291]]\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns document embeddings (numpy array) of shape \f[B](n_samples,
hiddenSize)\f[].
