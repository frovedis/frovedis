.TH "Linear SVM" "" "" "" ""
.SH NAME
.PP
Linear SVM (Support Vector Machines) \- A classification algorithm to
predict the binary output with hinge loss.
.SH SYNOPSIS
.PP
class frovedis.mllib.svm.LinearSVC(penalty=\[aq]l2\[aq],
loss=\[aq]hinge\[aq], dual=True,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  tol=1e\-4, C=1.0,
multi_class=\[aq]ovr\[aq],
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  fit_intercept=True,
intercept_scaling=1,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  class_weight=None, verbose=0,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  random_state=None, max_iter=1000,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  lr_rate=0.01, solver=\[aq]sag\[aq],
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  warm_start=False)
.SS Public Member Functions
.PP
fit(X, y, sample_weight = None)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
score(X, y, sample_weight = None)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
Classification aims to divide items into categories.
The most common classification type is binary classification, where
there are two categories, usually named positive and negative.
\f[B]Frovedis supports only binary Linear SVM classification
algorithm\f[].
.PP
The Linear SVM is a standard method for large\-scale classification
tasks.
It is a linear method with the loss function given by the \f[B]hinge
loss\f[]:
.IP
.nf
\f[C]
L(w;x,y)\ :=\ max{0,\ 1\-ywTx}
\f[]
.fi
.PP
Where the vectors x are the training data examples and y are their
corresponding labels (Frovedis supports any values as for labels, but
internally it encodes the input binary labels to \-1 and 1, before
training at Frovedis server) which we want to predict.
w is the linear model (also known as weight) which uses a single
weighted sum of features to make a prediction.
Linear SVM supports ZERO, L1 and L2 regularization to address the
overfit problem.
.PP
The gradient of the hinge loss is: \-y.x, if ywTx < 1, 0 otherwise.
.PD 0
.P
.PD
The gradient of the L1 regularizer is: sign(w)
.PD 0
.P
.PD
And The gradient of the L2 regularizer is: w
.PP
For binary classification problems, the algorithm outputs a binary svm
model.
Given a new data point, denoted by x, the model makes predictions based
on the value of wTx.
.PP
By default (threshold=0), if wTx >= 0, then the response is positive
(1), else the response is negative (0).
.PP
Frovedis provides implementation of linear SVM with \f[B]stochastic
gradient descent with minibatch\f[].
.PP
The simplest method to solve optimization problems of the form \f[B]min
f(w)\f[] is gradient descent.
Such first\-order optimization methods well\-suited for large\-scale and
distributed computation.
.PP
This module provides a client\-server implementation, where the client
application is a normal python program.
Frovedis is almost same as Scikit\-learn svm module providing the
LinearSVC (Support Vector Classification) support, but it doesn\[aq]t
have any dependency with Scikit\-learn.
It can be used simply even if the system doesn\[aq]t have Scikit\-learn
installed.
Thus in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for LinearSVC on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When prediction\-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS LinearSVC()
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]penalty\f[]\f[]: A string object containing the regularizer
type to use.
Currently none, l1 and l2 are supported by Frovedis.
(Default: \[aq]l2\[aq])
.PD 0
.P
.PD
\f[I]\f[B]loss\f[]\f[]: A string object containing the loss function
type to use.
Currently svm supports only hinge loss.
(Default: \[aq]hinge\[aq])
.PD 0
.P
.PD
\f[I]\f[B]dual\f[]\f[]: A boolean parameter (unused)
.PD 0
.P
.PD
\f[I]\f[B]tol\f[]\f[]: A double(float64) parameter specifying the
convergence tolerance value.
It must be zero or a positive value.
(Default: 1e\-4)
.PD 0
.P
.PD
\f[I]\f[B]C\f[]\f[]: A float parameter, also called as inverse of
regularization strength.
It must be positive.
(Default: 1.0)
.PD 0
.P
.PD
\f[I]\f[B]multi_class\f[]\f[]: A string object specifying type of
classification.
(unused)
.PD 0
.P
.PD
\f[I]\f[B]fit_intercept\f[]\f[]: A boolean parameter specifying whether
a constant (intercept) should be added to the decision function.
(Default: True)
.PD 0
.P
.PD
\f[I]\f[B]intercept_scaling\f[]\f[]: An integer parameter.
(unused)
.PD 0
.P
.PD
\f[I]\f[B]class_weight\f[]\f[]: A python dictionary or a string object.
(unused)
.PD 0
.P
.PD
\f[I]\f[B]verbose\f[]\f[]: An integer parameter specifying the log level
to use.
Its value is set as 0 by default(for INFO mode).
But it can be set to 1(for DEBUG mode) or 2(for TRACE mode) for getting
training time logs from frovedis server.
.PD 0
.P
.PD
\f[I]\f[B]random_state\f[]\f[]: An integer, None or RandomState
instance.
(unused)
.PD 0
.P
.PD
\f[I]\f[B]max_iter\f[]\f[]: An integer parameter specifying maximum
iteration count.
It is positive interger.
(Default: 1000)
.PD 0
.P
.PD
\f[I]\f[B]lr_rate\f[]\f[]: A double(float64) parameter containing the
learning rate.
(Default: 0.01)
.PD 0
.P
.PD
\f[I]\f[B]solver\f[]\f[]: A string object specifying the solver to use.
(Default: \[aq]sag\[aq])
.PD 0
.P
.PD
“sag” handle L1, L2 or no penalty.
.PD 0
.P
.PD
\f[I]\f[B]warm_start\f[]\f[]: A boolean parameter which when set to
True, reuses the solution of the previous call to fit as initialization,
otherwise, just erase the previous solution.
(Default: False)
.PP
\f[B]Attributes\f[]
.PD 0
.P
.PD
\f[I]\f[B]coef_\f[]\f[]: It is a python ndarray(containing float or
double(float64) typed values depending on data\-type of input matrix
(X)).
It is the weights assigned to the features.
It has shape (1, n_features).
.PD 0
.P
.PD
\f[I]\f[B]classes_\f[]\f[]: It is a python ndarray(any type) of unique
labels given to the classifier during training.
It has shape (n_classes,).
.PD 0
.P
.PD
\f[I]\f[B]intercept_\f[]\f[]: It is a python ndarray(float or
double(float64) values depending on input matrix data type) and has
shape(1,).
.PD 0
.P
.PD
\f[I]\f[B]n_iter\f[]\f[]: It is a python ndarray of shape(1,) and has
integer data.
It is used to get the actual iteration point at which the problem is
converged.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It initializes a LinearSVC object with the given parameters.
.PP
The parameters: "dual", "intercept_scaling", "class_weight",
"multi_class"and "random_state" are simply kept to make the interface
uniform to Scikit\-learn LinearSVC module.
They are not used anywhere within frovedis implementation.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS fit(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisColmajorMatrix for dense data.
It has shape(n_samples, n_features).
.PD 0
.P
.PD
\f[I]\f[B]y\f[]\f[]: Any python array\-like object or an instance of
FrovedisDvector.
.PD 0
.P
.PD
\f[I]\f[B]sample_weight\f[]\f[]: Python array\-like containing the
intended weights for each input samples and it should be the shape of
(nsamples, ).
When it is None (not specified), an uniform weight vector is assigned on
each input sample.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the training feature matrix (X) and corresponding output
labels (y) as inputs from the user and trains a linear svm model with
specifed regularization with those data at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ a\ sample\ matrix\ and\ labels\ data
from\ sklearn.datasets\ import\ load_breast_cancer
mat,\ lbl\ =\ load_breast_cancer(return_X_y\ =\ True)

#\ fitting\ input\ matrix\ and\ label\ on\ linear\ SVC\ object
from\ frovedis.mllib.svm\ import\ LinearSVC
svm\ =\ LinearSVC().fit(mat,\ lbl)
\f[]
.fi
.PP
When native python data is provided, it is converted to frovedis\-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre\-constructed frovedis\-like inputs can be used to speed up the
training time, specially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ a\ sample\ matrix\ and\ labels\ data
from\ sklearn.datasets\ import\ load_breast_cancer
mat,\ lbl\ =\ load_breast_cancer(return_X_y\ =\ True)

#\ Since\ "mat"\ is\ numpy\ dense\ data,\ we\ have\ created\ FrovedisColmajorMatrix.
and\ for\ scipy\ sparse\ data,\ FrovedisCRSMatrix\ should\ be\ used.\ 
from\ frovedis.matrix.dense\ import\ FrovedisColmajorMatrix
from\ frovedis.matrix.dvector\ import\ FrovedisDvector
cmat\ =\ FrovedisColmajorMatrix(mat)

#\ Linear\ SVC\ with\ pre\-constructed\ frovedis\-like\ inputs
from\ frovedis.mllib.svm\ import\ LinearSVC
svm\ =\ LinearSVC().fit(cmat,dlbl)
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS predict(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape(n_samples, n_features).
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
svm.predict(mat)\ \ 
\f[]
.fi
.PP
Output:
.IP
.nf
\f[C]
[0\ 0\ 0\ ...\ 0\ 0\ 1]\ \ 
\f[]
.fi
.PP
If the above pre\-constructed training data (cmat) is to be used during
prediction, the same can be used as follows:
.IP
.nf
\f[C]
#\ predicting\ on\ LinearSVC\ using\ pre\-constructed\ input
svm.predict(cmat.to_frovedis_rowmatrix())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ ...\ 0\ 0\ 1]\ \ \ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of double(float64) type containing the
predicted outputs.
It has shape(n_samples,).
.SS load(fname, dtype = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]fname\f[]: A string object containing the name of the file having
model information to be loaded.
.PD 0
.P
.PD
\f[B]dtype\f[]: A data\-type is inferred from the input data.
Currently, expected input data\-type is either float or double(float64).
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It loads the model from the specified file(having little\-endian binary
data).
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ the\ svc\ model
svm.load("./out/SVMModel")
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" instance.
.SS save(fname)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]fname\f[]: A string object containing the name of the file on which
the target model is to be saved.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
On success, it writes the model information (weight values etc.) in the
specified file as little\-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
#\ saving\ the\ model
svm.save("./out/SVMModel")
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS score(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]X\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape(n_samples, n_features).
.PD 0
.P
.PD
\f[B]y\f[]: Any python array\-like object or an instance of
FrovedisDvector.
.PD 0
.P
.PD
\f[B]sample_weight\f[]: Python array\-like containing the intended
weights for each input samples and it should be the shape of (nsamples,
).
When it is None (not specified), an uniform weight vector is assigned on
each input sample.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Calculate mean accuracy on the given test data and labels i.e.
mean accuracy of self.predict(X) wrt.
y.
.PP
For example,
.IP
.nf
\f[C]
\ #\ calculate\ mean\ accuracy\ score\ on\ given\ test\ data\ and\ labels
\ svm.score(mat,\ lbl)
\ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
0.63\ \ 
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns an accuracy score of float type.
.SS debug_print()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It shows the target model information(weight values etc.) on the server
side user terminal.
It is mainly used for debugging purpose.
.PP
For example,
.IP
.nf
\f[C]
svm.debug_print()\ 
\f[]
.fi
.PP
Output:
.IP
.nf
\f[C]
\-\-\-\-\-\-\-\-\ Weight\ Vector::\ \-\-\-\-\-\-\-\-
\ 83.7418\ 122.163\ 486.84\ 211.922\ 1.32991\ 0.287324\ \-0.867741\ \-0.0505454\ 
\ 2.04889\ 1.16388\ 0.750738\ 8.61861\ \-2.13628\ \-234.118\ 0.582984\ 0.445561\ 
\ 0.353854\ 0.519177\ 0.667717\ 0.547778\ 89.3196\ 157.824\ 499.367\ 
\ \-293.736\ 1.56023\ \-0.636429\ \-2.30027\ \-0.061839\ 2.66517\ 1.15244\ \ 
\ Intercept::\ 19.3242
\ Threshold::\ 0
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS release()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to release the in\-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
svm.release()
\f[]
.fi
.PP
This will reset the after\-fit populated attributes to None, along with
releasing server side memory.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS is_fitted()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, predict() is used before training the model, then it can prompt
the user to train the model first.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns ‘True', if the model is already fitted otherwise, it returns
‘False'.
.SH SEE ALSO
.PP
logistic_regression, dvector, crs_matrix
