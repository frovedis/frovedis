.TH "FactorizationMachineClassifier" "" "" "" ""
.SH NAME
.PP
FactorizationMachineClassifier \- A factorization machine is a
general\-purpose supervised learning algorithm that can be used for
classification tasks.
It is an extension of a linear model that is designed to capture
interactions between features within high dimensional sparse datasets.
.SH SYNOPSIS
.IP
.nf
\f[C]
class\ frovedis.mllib.fm.FactorizationMachineClassifier(iteration=100,\ init_stdev=0.1,\ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ init_learn_rate=0.01,\ optimizer=“SGD”,\ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dim=(True,True,\ 8),\ reg=(0,\ 0,\ 0),\ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ batch_size_pernode=100,\ verbose=0)\ \ 
\f[]
.fi
.SS Public Member Functions
.PP
fit(X, y, sample_weight = None)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
score(X, y, sample_weight = None)
.PD 0
.P
.PD
save(fname) get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
The FactorizationMachineClassifier (fmc) is a general predictor like
SVMs but is also able to estimate reliable parameters under very high
sparsity.
The factorization machine models all nested variable interactions
(comparable to a polynomial kernel in SVM), but uses a factorized
parameterization instead of a dense parametrization like in SVMs.
We show that the model equation of fmcs can be computed in linear time
and that it depends only on a linear number of parameters.
This allows direct optimization and storage of model parameters without
the need of storing any training data (e.g.
support vectors) for prediction.
\f[B]Frovedis supports both binary and multinomial labels.\f[]
.PP
During training, the input \f[B]X\f[] is the training data and
\f[B]y\f[] are their corresponding label values (Frovedis supports any
values as for labels, but internally it encodes the input binary labels
to \-1 and 1, before training at Frovedis server) which we want to
predict.
.PP
This module provides a client\-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as libFM.
libFM is a software implementation for factorization machines that
features stochastic gradient descent (SGD) and alternating least squares
(ALS) optimization as well as Bayesian inference using Markov Chain
Monte Carlo (MCMC).
In this implementation, a python client can interact with a frovedis
server sending the required python data for training at frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for FactorizationMachineClassifier on the frovedis
server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When predict\-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. FactorizationMachineClassifier()
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]iteration\f[]\f[]: A positive integer parameter, specifying
the maximum number of iteration count.
(Default: 100)
.PD 0
.P
.PD
\f[B]\f[I]init_stdev\f[]\f[]: A positive double parameter specifying the
standard deviation which is used to initialize the model parameter of
2\-way factors.
(Default: 0.1)
.PD 0
.P
.PD
\f[B]\f[I]init_learn_rate\f[]\f[]: A double parameter containing the
learning rate for SGD optimizer.
(Default: 0.01)
.PD 0
.P
.PD
It should be in range from 0.00001 to 1.0.
.PD 0
.P
.PD
\f[B]\f[I]optimizer\f[]\f[]: A string object parameter that specifies
which algorithms minimize or maximize a Loss function E(x) using its
gradient values with respect to the parameters.
(Default: \[aq]SGD\[aq])
.PD 0
.P
.PD
Only \[aq]SGD\[aq] is supported.
.PD 0
.P
.PD
\f[B]\f[I]dim\f[]\f[]: A tuple that specifies three important parameters
with default values\- (True, True,8):
.PD 0
.P
.PD
\- \f[B]\f[I]global_bias\f[]\f[]: A boolean value that represents a
switch to use bias.
Currently, this parameter is not used in Frovedis implementation.
.PD 0
.P
.PD
\- \f[B]\f[I]dim_one_interactions\f[]\f[] : A boolean value represents a
switch to use 1\-way interaction.
.PD 0
.P
.PD
\- \f[B]\f[I]dim_factors_no\f[]\f[] : A positive integer that represents
the dimension of 2\-way interaction or number of factors that are used
for pairwise interactions.
.PP
When any of the three is None (not specified explicitly), then user
experiences an Error.
.PD 0
.P
.PD
\f[B]\f[I]reg\f[]\f[]: A tuple that specifies three important parameters
with default values\- (Default: (0, 0, 0))
.PD 0
.P
.PD
\- \f[B]\f[I]regularization_intercept\f[]\f[] : A positive integer that
represents the regularization parameters of intercept or bias
regularization.
.PD 0
.P
.PD
\- \f[B]\f[I]regularization_one_interactions\f[]\f[] : A positive
integer that represents the switch to use 1\-way regularization.
.PD 0
.P
.PD
\- \f[B]\f[I]regularization_factors_no\f[]\f[] : A positive integer that
represents the dimension of 2\-way interaction or number of factors that
are used for pairwise regularization.
.PP
When any of the three is None (not specified explicitly), then user
experiences an Error.
.PD 0
.P
.PD
\f[B]\f[I]batch_size_pernode\f[]\f[]: A positive integer parameter
specifies the size of minibatch processed by one node.
(Default: 100)
.PD 0
.P
.PD
\f[B]\f[I]verbose\f[]\f[]: An integer parameter specifying the log level
to use.
Its value is set as 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PP
\f[B]Attributes\f[]
.PD 0
.P
.PD
\f[B]\f[I]classes_\f[]\f[]: A numpy array of long (int64) type value
that specifies unique labels given to the classifier during training.
It has shape \f[B](n_classes,)\f[], where n_classes is the unique number
of classes.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It initializes a FactorizationMachineClassifier object with the given
parameters.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 2. fit(X, y, sample_weight=None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A scipy sparse matrix or an instance of
FrovedisCRSMatrix of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[].
.PD 0
.P
.PD
\f[I]\f[B]y\f[]\f[]: Any python array\-like object or an instance of
FrovedisDvector containing the target labels.
It has shape \f[B](n_samples,)\f[].
.PD 0
.P
.PD
\f[B]\f[I]sample_weight\f[]\f[]: A python ndarray containing the
intended weights for each input samples and it should be the shape of
\f[B](n_samples,)\f[].
(Default: None)
.PD 0
.P
.PD
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the training matrix (X) with labels (y) and trains a
FactorizationMachineClassifier model.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ data\ \ \ 
row\ =\ np.array([0,\ 0,\ 0,\ 1,\ 1,\ 1,\ 1,\ 2,\ 2,\ 2,\ 3,\ 3,\ 3,\ 3,\ 4,\ 4,\ 4,\ 4,\ 5,\ 5])
col\ =\ np.array([0,\ 1,\ 4,\ 0,\ 1,\ 2,\ 4,\ 1,\ 2,\ 3,\ 2,3,4,5,\ 0,\ 1,\ 3,\ 4,\ 3,\ 5])
data\ =\ np.asarray([\ 2.0,\ 1.0,1.0,\ 1.0,\ 3.0,1.0,\ 1.0,\ 1.0,\ 2.0,1.0,\ 1.0,\ 3.0,
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 1.0,1.0,1.0,\ 1.0,\ 1.0,\ 3.0,1.0,\ 1.0])
csr\ =\ csr_matrix((data,\ (row,\ col)),\ shape\ =\ (6,\ 6))
lbl\ =\ [10.0,\ 10.0,\ 10.0,\ 20.0,\ 10.0,\ 20.0]

#\ fitting\ input\ data\ on\ FactorizationMachineClassifier\ object
from\ frovedis.mllib.fm\ import\ FactorizationMachineClassifier
fmc\ =\ FactorizationMachineClassifier()
fmc.fit(csr,\ lbl)
\f[]
.fi
.PP
When native python data is provided, it is converted to frovedis\-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre\-constructed frovedis\-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ sample\ data
row\ =\ np.array([0,\ 0,\ 0,\ 1,\ 1,\ 1,\ 1,\ 2,\ 2,\ 2,\ 3,\ 3,\ 3,\ 3,\ 4,\ 4,\ 4,\ 4,\ 5,\ 5])
col\ =\ np.array([0,\ 1,\ 4,\ 0,\ 1,\ 2,\ 4,\ 1,\ 2,\ 3,\ 2,3,4,5,\ 0,\ 1,\ 3,\ 4,\ 3,\ 5])
data\ =\ np.asarray([\ 2.0,\ 1.0,1.0,\ 1.0,\ 3.0,1.0,\ 1.0,\ 1.0,\ 2.0,1.0,\ 1.0,\ 3.0,
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 1.0,1.0,1.0,\ 1.0,\ 1.0,\ 3.0,1.0,\ 1.0])
csr\ =\ csr_matrix((data,\ (row,\ col)),\ shape\ =\ (6,\ 6))
lbl\ =\ [10.0,\ 10.0,\ 10.0,\ 20.0,\ 10.0,\ 20.0]

#\ Since\ "csr"\ is\ scipy\ sparse\ data,\ we\ have\ created\ FrovedisCRSMatrix.\ 
from\ frovedis.matrix.crs\ import\ FrovedisCRSMatrix
from\ frovedis.matrix.dvector\ import\ FrovedisDvector
cmat\ =\ FrovedisCRSMatrix(csr)
dlbl\ =\ FrovedisDvector(lbl)

#\ fitting\ input\ data\ on\ FactorizationMachineClassifier\ object
from\ frovedis.mllib.fm\ import\ FactorizationMachineClassifier
fmc\ =\ FactorizationMachineClassifier()
fmc.fit(cmat,\ dlbl)
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 3. predict(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A scipy sparse matrix or an instance of
FrovedisCRSMatrix of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It accepts the test feature matrix (X) in order to make prediction on
the trained model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
#\ predicting\ on\ FactorizationMachineClassifier\ model
fmc.predict(csr)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[20.\ 20.\ 20.\ 20.\ 20.\ 20.]
\f[]
.fi
.PP
Like in fit(), frovedis\-like input can be used to speed\-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
#\ Since\ "csr"\ is\ scipy\ sparse\ data,\ we\ have\ created\ FrovedisCRSMatrix.\ 
from\ frovedis.matrix.crs\ import\ FrovedisCRSMatrix
cmat\ =\ FrovedisCRSMatrix(csr)
\ 
#\ predicting\ on\ FactorizationMachineClassifier\ model\ using\ pre\-constructed\ input
fmc.predict(cmat)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[20.\ 20.\ 20.\ 20.\ 20.\ 20.]
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of double (float64) type containing the
predicted outputs.
It is of shape \f[B](n_samples,)\f[].
.SS 4. load(fname, dtype = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]fname\f[]\f[]: A string object containing the name of the file
having model information to be loaded.
.PD 0
.P
.PD
\f[B]\f[I]dtype\f[]\f[]: A data\-type is inferred from the input data.
Currently, expected input data\-type is either float or double
(float64).
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Currently, this method is not supported for
FactorizationMachineClassifier.
It is simply kept in FactorizationMachineClassifier module to maintain
uniform interface like other estimators in frovedis.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply raises an AttributeError.
.SS 5. score(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A scipy sparse matrix or an instance of
FrovedisCRSMatrix of float or double (float64) type.
It has shape \f[B](n_samples, n_features)\f[].
.PD 0
.P
.PD
\f[B]\f[I]y\f[]\f[]: Any python array\-like object containing class
labels.
It is of shape \f[B](n_samples,)\f[].
.PD 0
.P
.PD
\f[B]\f[I]sample_weight\f[]\f[]: A python ndarray containing the
intended weights for each input samples and it should be the shape of
\f[B](n_samples,)\f[].
(Default: None)
.PD 0
.P
.PD
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Calculate mean accuracy on the given test data and labels i.e.
mean accuracy of self.predict(X) wrt.
y.
.PP
For example,
.IP
.nf
\f[C]
fmc.score(csr,\ lbl)
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
0.83
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns an accuracy score of double (float64) type.
.SS 6. save(fname)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]fname\f[]\f[]: A string object containing the name of the file
on which the target model is to be saved.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
On success, it writes the model information(label_map, metadata and
model) in the specified file as little\-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
#\ To\ save\ the\ FactorizationMachineClassifier\ model
fmc.save("./out/FMCModel")
\f[]
.fi
.PP
The FMCModel contains below directory structure:
.PD 0
.P
.PD
\f[B]FMCModel\f[]
.PD 0
.P
.PD
|\-\-\-\-\-\-label_map
.PD 0
.P
.PD
|\-\-\-\-\-\-metadata
.PD 0
.P
.PD
|\-\-\-\-\-\-model
.PP
\[aq]label_map\[aq] contains information about labels mapped with their
encoded value.
.PD 0
.P
.PD
\[aq]metadata\[aq] represents the detail about model_kind and datatype
of training vector.
.PD 0
.P
.PD
Here, the model file contains information about trained model in binary
format.
.PP
This will save the FactorizationMachineClassifier model on the path
‘/out/FMCModel'.
It would raise exception if the directory already exists with same name.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 7. get_params(deep = True)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]deep\f[]\f[]: A boolean parameter, used to get parameters and
their values for an estimator.
If True, it will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
FactorizationMachineClassifier.
It is used to get parameters and their values of
FactorizationMachineClassifier class.
.PP
For example,
.IP
.nf
\f[C]
print(fmc.get_params())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]batch_size_pernode\[aq]:\ 100,\ \[aq]dim\[aq]:\ (True,\ True,\ 8),\ \[aq]init_learn_rate\[aq]:\ 0.01,\ 
\[aq]init_stdev\[aq]:\ 0.1,\ \[aq]iteration\[aq]:\ 100,\ \[aq]optimizer\[aq]:\ \[aq]SGD\[aq],\ \[aq]reg\[aq]:\ (0,\ 0,\ 0),\ 
\[aq]verbose\[aq]:\ 0}
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 8. set_params(**params)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]**params\f[]\f[]: All the keyword arguments are passed this
function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
FactorizationMachineClassifier, used to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print("Get\ parameters\ before\ setting:")\ 
print(fmc.get_params())
#\ User\ just\ needs\ to\ provide\ the\ arguments\ and\ internally\ it\ will\ create\ a\ 
dictionary\ over\ the\ arguments\ given\ by\ user
fmc.set_params(iteration\ =\ 200)\ 
print("Get\ parameters\ after\ setting:")\ 
print(fmc.get_params())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
Get\ parameters\ before\ setting:\ 
{\[aq]batch_size_pernode\[aq]:\ 100,\ \[aq]dim\[aq]:\ (True,\ True,\ 8),\ \[aq]init_learn_rate\[aq]:\ 0.01,\ 
\[aq]init_stdev\[aq]:\ 0.1,\ \[aq]iteration\[aq]:\ 100,\ \[aq]optimizer\[aq]:\ \[aq]SGD\[aq],\ \[aq]reg\[aq]:\ (0,\ 0,\ 0),\ 
\[aq]verbose\[aq]:\ 0}
Get\ parameters\ after\ setting:\ 
{\[aq]batch_size_pernode\[aq]:\ 100,\ \[aq]dim\[aq]:\ (True,\ True,\ 8),\ \[aq]init_learn_rate\[aq]:\ 0.01,\ 
\[aq]init_stdev\[aq]:\ 0.1,\ \[aq]iteration\[aq]:\ 200,\ \[aq]optimizer\[aq]:\ \[aq]SGD\[aq],\ \[aq]reg\[aq]:\ (0,\ 0,\ 0),\ 
\[aq]verbose\[aq]:\ 0}
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 9. debug_print()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Currently, this method is not supported for
FactorizationMachineClassifier.
It is simply kept in FactorizationMachineClassifier module to maintain
uniform interface like other estimators in frovedis.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply raises an AttributeError.
.SS 10. release()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to release the in\-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
fmc.release()
\f[]
.fi
.PP
This will reset the after\-fit populated attributes to None, along with
releasing server side memory.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 11. is_fitted()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
In case, predict() is used before training the model, then it can prompt
the user to train the model first.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns \[aq]True\[aq], if the model is already fitted otherwise, it
returns \[aq]False\[aq].
.SH SEE ALSO
.PP
crs_matrix, dvector, fm_regressor
