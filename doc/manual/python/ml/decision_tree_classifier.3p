.TH "DecisionTreeClassifier" "" "" "" ""
.SH NAME
.PP
DecisionTreeClassifier \- A classification algorithm that predicts the
binary and multi\-class output using conditional control statements.
A decision tree is a decision support tool that uses a tree\-like model
of decisions and their possible consequences, including chance, event,
outcomes, resource costs, and utility.
.SH SYNOPSIS
.PP
class
frovedis.mllib.tree.DecisionTreeClassifier(criterion=\[aq]gini\[aq],
splitter=\[aq]best\[aq], max_depth=None,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ min_samples_split=2,
min_samples_leaf=1,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ min_weight_fraction_leaf=0.0,
max_features=None,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ random_state=None,
max_leaf_nodes=None,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ min_impurity_decrease=0.0,
class_weight=None,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ presort=\[aq]deprecated\[aq],
ccp_alpha=0.0,
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max_bins=32, verbose=0,
categorical_info={})
.SS Public Member Functions
.PP
fit(X, y)
.PD 0
.P
.PD
predict(X)
.PD 0
.P
.PD
predict_proba(X)
.PD 0
.P
.PD
get_params(deep = True)
.PD 0
.P
.PD
set_params(**params)
.PD 0
.P
.PD
load(fname, dtype = None)
.PD 0
.P
.PD
save(fname)
.PD 0
.P
.PD
score(X, y, sample_weight = None)
.PD 0
.P
.PD
debug_print()
.PD 0
.P
.PD
release()
.PD 0
.P
.PD
is_fitted()
.SH DESCRIPTION
.PP
Decision Tree Classifier is a supervised learning method used for
classification problems.
The aim is to create a model that predicts the value of a target
variable by learning simple decision rules inferred from the data
features.
Like any other tree representation, it has a root node, internal nodes,
and leaf nodes.
The internal node represents condition on attributes, the branches
represent the results of the condition and the leaf node represents the
class label.
\f[B]Frovedis supports both binary and multinomial decision tree
classification algorithms.\f[]
.PP
During training, the input \f[B]X\f[] is the training data and
\f[B]y\f[] is the corresponding label values (Frovedis supports any
values for labels, but internally it encodes the input binary labels to
0 and 1, and input multinomial labels to 0, 1, 2, ..., N\-1 (where N is
the no.
of classes) before training at Frovedis server) which we want to
predict.
.PP
This module provides a client\-server implementation, where the client
application is a normal python program.
The frovedis interface is almost same as Scikit\-learn
DecisionTreeClassifier interface, but it doesn\[aq]t have any dependency
with Scikit\-learn.
It can be used simply even if the system doesn\[aq]t have Scikit\-learn
installed.
Thus in this implementation, a python client can interact with a
frovedis server sending the required python data for training at
frovedis side.
Python data is converted into frovedis compatible data internally and
the python ML call is linked with the respective frovedis ML call to get
the job done at frovedis server.
.PP
Python side calls for DecisionTreeClassifier on the frovedis server.
Once the training is completed with the input data at the frovedis
server, it returns an abstract model with a unique model ID to the
client python program.
.PP
When prediction\-like request would be made on the trained model, python
program will send the same request to the frovedis server.
After the request is served at the frovedis server, the output would be
sent back to the python client.
.SS Detailed Description
.SS 1. DecisionTreeClassifier()
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]criterion\f[]\f[]: A string object parameter that specifies
the function to measure the quality of a split.
Supported criteria are \[aq]gini\[aq] and \[aq]entropy\[aq].
(Deault: \[aq]gini\[aq])
.PD 0
.P
.PD
\[aq]gini\[aq] impurity: calculates the amount of probability of a
specific feature that is classified incorrectly when selected randomly.
.PD 0
.P
.PD
\[aq]entropy\[aq] (information gain): it is applied to quantify which
feature provides maximal information about the classification based on
the notion of entropy.
.PD 0
.P
.PD
\f[B]\f[I]splitter\f[]\f[]: An unused parameter.
(Default: \[aq]best\[aq])
.PD 0
.P
.PD
\f[B]\f[I]max_depth\f[]\f[]: A positive integer parameter that specifies
the maximum depth of the tree.
.PD 0
.P
.PD
If it is None (not specified explicitly), then \[aq]max_depth\[aq] is
set to 5.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]min_samples_split\f[]\f[]: An unused parameter.
(Default: 2)
.PD 0
.P
.PD
\f[B]\f[I]min_samples_leaf\f[]\f[]: A positive integer or float value
that specifies the minimum number of samples required to be at a leaf
node.
A split point at any depth will only be considered if it leaves at least
\[aq]min_samples_leaf\[aq] training samples in each of the left and
right branches.
(Default: 1)
.PD 0
.P
.PD
If it is an integer, then \[aq]min_samples_leaf\[aq] should be greater
than or equal to 1.
.PD 0
.P
.PD
If it is float, then \[aq]min_samples_leaf\[aq] should be in range
(0,0.5].
.PD 0
.P
.PD
\f[B]\f[I]min_weight_fraction_leaf\f[]\f[]: An unused parameter.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[I]max_features\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]random_state\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]max_leaf_nodes\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]min_impurity_decrease\f[]\f[]: A positive double (float64)
parameter.
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[I]class_weight\f[]\f[]: An unused parameter.
(Default: None)
.PD 0
.P
.PD
\f[B]\f[I]presort\f[]\f[]: An unused parameter.
(Default: \[aq]deprecated\[aq])
.PD 0
.P
.PD
\f[B]\f[I]ccp_alpha\f[]\f[]: An unused parameter.
(Default: 0.0)
.PD 0
.P
.PD
\f[B]\f[I]max_bins\f[]\f[]: A positive integer parameter that specifies
the maximum number of bins created by ordered splits.
(Default: 32)
.PD 0
.P
.PD
\f[B]\f[I]verbose\f[]\f[]: An integer parameter specifying the log level
to use.
Its value is set as 0 by default (for INFO mode).
But it can be set to 1 (for DEBUG mode) or 2 (for TRACE mode) for
getting training time logs from frovedis server.
.PD 0
.P
.PD
\f[B]\f[I]categorical_info\f[]\f[]: A dictionary that specifies
categorical features information.
Here, it gives column indices of categorical features and the number of
categories for those features.
.PD 0
.P
.PD
For example, a dictionary { {0, 2}, {4, 5} } means that the feature[0]
takes values 0 or 1 (binary) and the feature[4] has five categories
(values 0, 1, 2, 3 or 4).
Note that feature indices and category assignments are 0\-based.
(Default: {})
.PP
\f[B]Attributes\f[]
.PD 0
.P
.PD
\f[B]\f[I]classes_\f[]\f[]: It is a python ndarray(any type) of unique
labels given to the classifier during training.
It has shape \f[B](n_classes,)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It initializes a DecisionTreeClassifier object with the given
parameters.
.PP
The parameters: "splitter", "min_samples_split",
"min_weight_fraction_leaf", "max_features", "random_state",
"max_leaf_nodes", "class_weight", "presort" and "ccp_alpha" are simply
kept in to make the interface uniform to the Scikit\-learn
DecisionTreeClassifier module.
They are not used anywhere within frovedis implementation.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 2. fit(X, y)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisColmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PD 0
.P
.PD
\f[B]\f[I]y\f[]\f[]: Any python array\-like object or an instance of
FrovedisDvector.
It has shape \f[B](n_samples,)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It builds a decision tree classifier from the training data X and labels
y.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ a\ sample\ matrix\ and\ labels\ data
from\ sklearn.datasets\ import\ load_breast_cancer
mat,\ lbl\ =\ load_breast_cancer(return_X_y\ =\ True)

#\ fitting\ input\ matrix\ and\ label\ on\ DecisionTreeClassifier\ object
from\ frovedis.mllib.tree\ import\ DecisionTreeClassifier
dtc\ =\ DecisionTreeClassifier(max_depth\ =\ 5)
dtc.fit(mat,lbl)
\f[]
.fi
.PP
When native python data is provided, it is converted to frovedis\-like
inputs and sent to frovedis server which consumes some data transfer
time.
Pre\-constructed frovedis\-like inputs can be used to speed up the
training time, especially when same data would be used for multiple
executions.
.PP
For example,
.IP
.nf
\f[C]
#\ loading\ a\ sample\ matrix\ and\ labels\ data
from\ sklearn.datasets\ import\ load_breast_cancer
mat,\ lbl\ =\ load_breast_cancer(return_X_y\ =\ True)

#\ Since\ "mat"\ is\ numpy\ dense\ data,\ we\ have\ created\ FrovedisColmajorMatrix.\ 
#\ For\ scipy\ sparse\ data,\ FrovedisCRSMatrix\ should\ be\ used\ instead.
from\ frovedis.matrix.dense\ import\ FrovedisColmajorMatrix
from\ frovedis.matrix.dvector\ import\ FrovedisDvector\ 
cmat\ =\ FrovedisColmajorMatrix(mat)
dlbl\ =\ FrovedisDvector(lbl)

#\ DecisionTreeClassifier\ with\ pre\-constructed\ frovedis\-like\ inputs
from\ frovedis.mllib.tree\ import\ DecisionTreeClassifier
dtc\ =\ DecisionTreeClassifier(max_depth\ =\ 5)
dtc.fit(cmat,dlbl)
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 3. predict(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Predict class for X.
.PP
For a classification model, the predicted class value for each sample in
X is returned.
.PP
For example,
.IP
.nf
\f[C]
#\ predicting\ on\ decision\ tree\ classifier\ model
dtc.predict(mat)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ ...\ 0\ 0\ 1]
\f[]
.fi
.PP
Like in fit(), frovedis\-like input can be used to speed\-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
#\ Since\ "cmat"\ is\ FrovedisColmajorMatrix,\ we\ have\ created\ FrovedisRowmajorMatrix.
from\ frovedis.matrix.dense\ import\ FrovedisRowmajorMatrix

#\ predicting\ on\ decision\ tree\ classifier\ model\ using\ pre\-constructed\ input
dtc.predict(cmat.to_frovedis_rowmatrix())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[0\ 0\ 0\ ...\ 0\ 0\ 1]
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of float or double (float64) type and of shape
\f[B](n_samples,)\f[] containing the predicted classes.
.SS 4. predict_proba(X)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Predict class log\-probabilities of the input samples X.
.PP
\f[B]Currently, this method is not supported for multinomial
classification problems.\f[]
.PP
For example,
.IP
.nf
\f[C]
#\ finds\ the\ probability\ sample\ for\ each\ class\ in\ the\ model
dtc.predict_proba(mat)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[[1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ ...
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [0.009375\ 0.990625]]
\f[]
.fi
.PP
Like in fit(), frovedis\-like input can be used to speed\-up the
prediction making on the trained model at server side.
.PP
For example,
.IP
.nf
\f[C]
#\ Since\ "cmat"\ is\ FrovedisColmajorMatrix,\ we\ have\ created\ FrovedisRowmajorMatrix.
from\ frovedis.matrix.dense\ import\ FrovedisRowmajorMatrix

#\ finds\ the\ probability\ sample\ for\ each\ class\ in\ the\ model
dtc.predict_proba(cmat.to_frovedis_rowmatrix())\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
[[1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ ...
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [1.\ \ \ \ \ \ \ 0.\ \ \ \ \ \ ]
\ [0.009375\ 0.990625]]
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns a numpy array of float or double(float64) type and of shape
\f[B](n_samples, n_classes)\f[] containing the prediction probability
values.
Here, \f[B]n_classes = 2\f[], since only binary classification problems
are supported for this method.
.SS 5. get_params(deep = True)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]deep\f[]\f[]: A boolean parameter, used to get parameters and
their values for an estimator.
If True, it will return the parameters for an estimator and contained
subobjects that are estimators.
(Default: True)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
DecisionTreeClassifier.
It is used to get parameters and their values of DecisionTreeClassifier
class.
.PP
For example,
.IP
.nf
\f[C]
\ \ print(dtc.get_params())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
{\[aq]categorical_info\[aq]:\ {},\ \[aq]ccp_alpha\[aq]:\ 0.0,\ \[aq]class_weight\[aq]:\ None,\ \[aq]criterion\[aq]:\ \[aq]GINI\[aq],\ 
\[aq]max_bins\[aq]:\ 32,\ \[aq]max_depth\[aq]:\ 5,\ \[aq]max_features\[aq]:\ None,\ \[aq]max_leaf_nodes\[aq]:\ None,\ 
\[aq]min_impurity_decrease\[aq]:\ 0.0,\ \[aq]min_samples_leaf\[aq]:\ 1,\ \[aq]min_samples_split\[aq]:\ 2,\ 
\[aq]min_weight_fraction_leaf\[aq]:\ 0.0,\ \[aq]presort\[aq]:\ \[aq]deprecated\[aq],\ \[aq]random_state\[aq]:\ None,\ 
\[aq]splitter\[aq]:\ \[aq]best\[aq],\ \[aq]verbose\[aq]:\ 0}
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
A dictionary of parameter names mapped to their values.
.SS 6. set_params(**params)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[I]\f[B]**params\f[]\f[]: All the keyword arguments are passed to this
function as dictionary.
This dictionary contains parameters of an estimator with its given
values to set.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
This method belongs to the BaseEstimator class inherited by
DecisionTreeClassifier, used to set parameter values.
.PP
For example,
.IP
.nf
\f[C]
print("get\ parameters\ before\ setting:")\ 
print(dtc.get_params())
#\ User\ just\ needs\ to\ provide\ the\ arguments\ and\ internally\ it\ will\ create\ a\ 
dictionary\ over\ the\ arguments\ given\ by\ user
dtc.set_params(criterion\ =\ \[aq]entropy\[aq],\ max_depth\ =\ 5)\ 
print("get\ parameters\ after\ setting:")\ 
print(dtc.get_params())
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
get\ parameters\ before\ setting:
{\[aq]categorical_info\[aq]:\ {},\ \[aq]ccp_alpha\[aq]:\ 0.0,\ \[aq]class_weight\[aq]:\ None,\ \[aq]criterion\[aq]:\ \[aq]GINI\[aq],\ 
\[aq]max_bins\[aq]:\ 32,\ \[aq]max_depth\[aq]:\ 5,\ \[aq]max_features\[aq]:\ None,\ \[aq]max_leaf_nodes\[aq]:\ None,\ 
\[aq]min_impurity_decrease\[aq]:\ 0.0,\ \[aq]min_samples_leaf\[aq]:\ 1,\ \[aq]min_samples_split\[aq]:\ 2,\ 
\[aq]min_weight_fraction_leaf\[aq]:\ 0.0,\ \[aq]presort\[aq]:\ \[aq]deprecated\[aq],\ \[aq]random_state\[aq]:\ None,\ 
\[aq]splitter\[aq]:\ \[aq]best\[aq],\ \[aq]verbose\[aq]:\ 0}
get\ parameters\ after\ setting:
{\[aq]categorical_info\[aq]:\ {},\ \[aq]ccp_alpha\[aq]:\ 0.0,\ \[aq]class_weight\[aq]:\ None,\ \[aq]criterion\[aq]:\ \[aq]entropy\[aq],\ 
\[aq]max_bins\[aq]:\ 32,\ \[aq]max_depth\[aq]:\ 5,\ \[aq]max_features\[aq]:\ None,\ \[aq]max_leaf_nodes\[aq]:\ None,\ 
\[aq]min_impurity_decrease\[aq]:\ 0.0,\ \[aq]min_samples_leaf\[aq]:\ 1,\ \[aq]min_samples_split\[aq]:\ 2,\ 
\[aq]min_weight_fraction_leaf\[aq]:\ 0.0,\ \[aq]presort\[aq]:\ \[aq]deprecated\[aq],\ \[aq]random_state\[aq]:\ None,\ 
\[aq]splitter\[aq]:\ \[aq]best\[aq],\ \[aq]verbose\[aq]:\ 0}
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 7. load(fname, dtype = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]fname\f[]\f[]: A string object containing the name of the file
having model information to be loaded.
.PD 0
.P
.PD
\f[B]\f[I]dtype\f[]\f[]: A data\-type is inferred from the input data.
Currently, expected input data\-type is either float or double
(float64).
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It loads the model from the specified file (having little\-endian binary
data).
.PP
For example,
.IP
.nf
\f[C]
dtc.load("./out/MyDecisionTreeClassifierModel")
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It simply returns "self" reference.
.SS 8. save(fname)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]fname\f[]\f[]: A string object containing the name of the file
on which the target model is to be saved.
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
On success, it writes the model information (after\-fit populated
attributes) in the specified file as little\-endian binary data.
Otherwise, it throws an exception.
.PP
For example,
.IP
.nf
\f[C]
#\ To\ save\ the\ decision\ tree\ classifier\ model
dtc.save("./out/MyDecisionTreeClassifierModel")\ \ 
\f[]
.fi
.PP
This will save the decision tree classifier model on the path
"/out/MyDecisionTreeClassifierModel".
It would raise exception if the directory already exists with same name.
.PP
The \[aq]MyDecisionTreeClassifierModel\[aq] directory has
.PP
\f[B]MyDecisionTreeClassifierModel\f[]
.PD 0
.P
.PD
|\-\-\-\-\-label_map
.PD 0
.P
.PD
|\-\-\-\-\-metadata
.PD 0
.P
.PD
|\-\-\-\-\-model
.PP
‘label_map' file contains information about labels mapped with their
encoded value.
.PD 0
.P
.PD
The \[aq]metadata\[aq] file contains the number of classes, model kind
and input datatype used for trained model.
.PD 0
.P
.PD
The \[aq]model\[aq] file contains the decision tree model saved in
binary format.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 9. score(X, y, sample_weight = None)
.PP
\f[B]Parameters\f[]
.PD 0
.P
.PD
\f[B]\f[I]X\f[]\f[]: A numpy dense or scipy sparse matrix or any python
array\-like object or an instance of FrovedisCRSMatrix for sparse data
and FrovedisRowmajorMatrix for dense data.
It has shape \f[B](n_samples, n_features)\f[].
.PD 0
.P
.PD
\f[B]\f[I]y\f[]\f[]: Any python array\-like object or an instance of
FrovedisDvector.
It has shape \f[B](n_samples,)\f[].
.PD 0
.P
.PD
\f[B]\f[I]sample_weight\f[]\f[]: Python ndarray containing the intended
weights for each input samples and it should be the shape of
\f[B](n_samples, )\f[].
When it is None (not specified explicitly), an uniform weight vector is
assigned on each input sample.
(Default: None)
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
Calculate mean accuracy on the given test data and labels i.e.
mean accuracy of self.predict(X) wrt.
y.
.PP
For example,
.IP
.nf
\f[C]
#\ calculate\ mean\ accuracy\ score\ on\ given\ test\ data\ and\ labels
dtc.score(mat,lbl)\ \ 
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
0.9895
\f[]
.fi
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns an accuracy score of float type.
.SS 10. debug_print()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It shows the target model information on the server side user terminal.
It is mainly used for debugging purpose.
.PP
For example,
.IP
.nf
\f[C]
dtc.debug_print()
\f[]
.fi
.PP
Output
.IP
.nf
\f[C]
\ \ \ \ \-\-\-\-\-\-\-\-\ Classification\ Tree::\ \-\-\-\-\-\-\-\-
#\ of\ nodes:\ 35,\ height:\ 5
<1>\ Split:\ feature[22]\ <\ 113.157,\ IG:\ 0.319406
\ \\_\ <2>\ Split:\ feature[27]\ <\ 0.144844,\ IG:\ 0.0626618
\ |\ \ \\_\ <4>\ Split:\ feature[22]\ <\ 107.223,\ IG:\ 0.00955662
\ |\ \ |\ \ \\_\ <8>\ Split:\ feature[10]\ <\ 0.904737,\ IG:\ 0.00582386
\ |\ \ |\ \ |\ \ \\_\ <16>\ Split:\ feature[27]\ <\ 0.133781,\ IG:\ 0.00558482
\ |\ \ |\ \ |\ \ |\ \ \\_\ (32)\ Predict:\ 1\ (99.0625%)
\ |\ \ |\ \ |\ \ |\ \ \\_\ (33)\ Predict:\ 1\ (66.6667%)
\ |\ \ |\ \ |\ \ \\_\ (17)\ Predict:\ 0\ (100%)
\ |\ \ |\ \ \\_\ <9>\ Split:\ feature[14]\ <\ 0.00570775,\ IG:\ 0.184704
\ |\ \ |\ \ \ \ \ \\_\ <18>\ Split:\ feature[0]\ <\ 14.0963,\ IG:\ 0.165289
\ |\ \ |\ \ \ \ \ |\ \ \\_\ (36)\ Predict:\ 0\ (100%)
\ |\ \ |\ \ \ \ \ |\ \ \\_\ (37)\ Predict:\ 1\ (100%)
\ |\ \ |\ \ \ \ \ \\_\ <19>\ Split:\ feature[21]\ <\ 21.9025,\ IG:\ 0.408163
\ |\ \ |\ \ \ \ \ \ \ \ \\_\ (38)\ Predict:\ 1\ (100%)
\ |\ \ |\ \ \ \ \ \ \ \ \\_\ (39)\ Predict:\ 0\ (100%)
\ |\ \ \\_\ <5>\ Split:\ feature[21]\ <\ 24.13,\ IG:\ 0.189372
\ |\ \ \ \ \ \\_\ <10>\ Split:\ feature[4]\ <\ 0.109085,\ IG:\ 0.32
\ |\ \ \ \ \ |\ \ \\_\ (20)\ Predict:\ 1\ (100%)
\ |\ \ \ \ \ |\ \ \\_\ (21)\ Predict:\ 0\ (100%)
\ |\ \ \ \ \ \\_\ <11>\ Split:\ feature[9]\ <\ 0.0609525,\ IG:\ 0.144027
\ |\ \ \ \ \ \ \ \ \\_\ (22)\ Predict:\ 1\ (100%)
\ |\ \ \ \ \ \ \ \ \\_\ <23>\ Split:\ feature[7]\ <\ 0.0404469,\ IG:\ 0.0907029
\ |\ \ \ \ \ \ \ \ \ \ \ \\_\ (46)\ Predict:\ 1\ (100%)
\ |\ \ \ \ \ \ \ \ \ \ \ \\_\ (47)\ Predict:\ 0\ (100%)
\ \\_\ <3>\ Split:\ feature[7]\ <\ 0.0509028,\ IG:\ 0.0364914
\ \ \ \ \\_\ <6>\ Split:\ feature[17]\ <\ 0.00995862,\ IG:\ 0.259286
\ \ \ \ |\ \ \\_\ <12>\ Split:\ feature[1]\ <\ 15.855,\ IG:\ 0.336735
\ \ \ \ |\ \ |\ \ \\_\ (24)\ Predict:\ 1\ (100%)
\ \ \ \ |\ \ |\ \ \\_\ (25)\ Predict:\ 0\ (100%)
\ \ \ \ |\ \ \\_\ (13)\ Predict:\ 1\ (100%)
\ \ \ \ \\_\ <7>\ Split:\ feature[1]\ <\ 13.9925,\ IG:\ 0.0116213
\ \ \ \ \ \ \ \\_\ <14>\ Split:\ feature[1]\ <\ 12.18,\ IG:\ 0.5
\ \ \ \ \ \ \ |\ \ \\_\ (28)\ Predict:\ 0\ (100%)
\ \ \ \ \ \ \ |\ \ \\_\ (29)\ Predict:\ 1\ (100%)
\ \ \ \ \ \ \ \\_\ (15)\ Predict:\ 0\ (100%)
\f[]
.fi
.PP
It displays the decision tree having maximum depth of 5 and total 35
nodes in the tree.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 11. release()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to release the in\-memory model at frovedis server.
.PP
For example,
.IP
.nf
\f[C]
dtc.release()
\f[]
.fi
.PP
This will reset the after\-fit populated attributes (like classes_) to
None, along with releasing server side memory.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns nothing.
.SS 12. is_fitted()
.PP
\f[B]Purpose\f[]
.PD 0
.P
.PD
It can be used to confirm if the model is already fitted or not.
.PP
\f[B]Return Value\f[]
.PD 0
.P
.PD
It returns ‘True', if the model is already fitted, otherwise, it returns
‘False'.
.SH SEE ALSO
.PP
dvector, crs_matrix, rowmajor_matrix, colmajor_matrix
